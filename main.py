# main.py
# -*- coding: utf-8 -*-
import streamlit as st
st.write("STREAMLIT BOOT OK")
from __future__ import annotations

import json
import math
import os
from dataclasses import dataclass
from datetime import datetime, timedelta, timezone
from typing import Dict, List, Optional, Tuple

import certifi
import numpy as np
import pandas as pd
import requests
import yfinance as yf

from market_amount import fetch_amount_total, intraday_norm, TZ_TAIPEI


# -----------------------------
# åŸºæœ¬è¨­å®šï¼ˆå…è²»/æ¨¡æ“¬æœŸï¼‰
# -----------------------------
SYSTEM_VERSION = "Predator V16.2 Enhanced (FREE/SIM)"
MARKET = "tw-share"

DEFAULT_UNIVERSE = [
    # å…ˆæ”¾é«˜æµå‹•æ€§ä»£è¡¨ï¼Œä¸¦æœƒè‡ªå‹•æŠŠæŒå€‰åŠ é€²ä¾†
    "2330.TW", "2317.TW", "2454.TW", "2308.TW", "2382.TW", "3231.TW",
    "2603.TW", "2609.TW", "2412.TW", "2881.TW", "2882.TW", "2891.TW",
    "1301.TW", "1303.TW", "2002.TW", "3711.TW", "5871.TW", "5880.TW",
    "3037.TW", "6669.TW",
]

USER_AGENT = {
    "User-Agent": "Mozilla/5.0 (compatible; SunheroStockBot/1.0; +https://github.com/)"
}

ALLOW_INSECURE_SSL = str(os.getenv("ALLOW_INSECURE_SSL", "0")).strip() in ("1", "true", "TRUE", "yes", "YES")

# Streamlit Cloud å¯ä»¥ç”¨ secrets
# st.secrets æœƒåœ¨ app.py ç”¨ï¼›main.py é€™è£¡ç´”å¾Œç«¯ä¸ä¾è³´ streamlit


# -----------------------------
# ä½éšå·¥å…·ï¼šrequestsï¼ˆå¸¶ certifiï¼Œå¿…è¦æ™‚é€€ verify=Falseï¼‰
# -----------------------------
def _requests_get(url: str, timeout: int = 15) -> requests.Response:
    try:
        return requests.get(url, headers=USER_AGENT, timeout=timeout, verify=certifi.where())
    except requests.exceptions.SSLError:
        if not ALLOW_INSECURE_SSL:
            raise
        return requests.get(url, headers=USER_AGENT, timeout=timeout, verify=False)


def _now_taipei() -> datetime:
    return datetime.now(tz=TZ_TAIPEI)


def _floor_int(x: float) -> int:
    return int(math.floor(x))


# -----------------------------
# äº¤æ˜“æ—¥ï¼šç”¨ ^TWII æœ€æ–°Kæ£’æ—¥æœŸç•¶ä½œã€Œæœ€å¾Œæ”¶ç›¤æ—¥ã€
# -----------------------------
def get_last_trade_date() -> str:
    df = yf.download("^TWII", period="10d", interval="1d", progress=False)
    if df is None or df.empty:
        # æœ€å·®é€€è·¯ï¼šç”¨ä»Šå¤©-1
        return (_now_taipei() - timedelta(days=1)).strftime("%Y-%m-%d")
    last_dt = df.index[-1].to_pydatetime()
    return last_dt.strftime("%Y-%m-%d")


def is_stale(last_trade_date: str, max_lag_trading_days: int = 1) -> bool:
    # ç”¨æ—¥æ›†ç²—ç•¥ä¼°ï¼šè½å¾Œ >2 å¤©é€šå¸¸ä¸å°ï¼›ä¿å®ˆé»ï¼šè‹¥è¶…é 2 å¤©ç›´æ¥è¦–ç‚º stale
    dt = datetime.strptime(last_trade_date, "%Y-%m-%d").replace(tzinfo=TZ_TAIPEI)
    lag_days = (_now_taipei().date() - dt.date()).days
    return lag_days > 2 or lag_days > (max_lag_trading_days + 1)


# -----------------------------
# ä¸­æ–‡åç¨±ï¼šæŠ“ TWSE/TPEx è‚¡ç¥¨æ¸…å–®åšå°ç…§ï¼ˆå…è²»ï¼‰
# -----------------------------
def fetch_twse_stock_names() -> Dict[str, str]:
    """
    TWSE ä¸Šå¸‚æ¸…å–®ï¼ˆç°¡ç‰ˆï¼‰ï¼šç”¨å…¬é–‹ CSV/JSON ä¾†æºå¯èƒ½æœƒè®Šï¼Œé€™è£¡åšã€Œå®¹éŒ¯å¼ã€æŠ“å–ã€‚
    å¤±æ•—å°±å›ç©º dictã€‚
    """
    out: Dict[str, str] = {}
    try:
        # å¸¸è¦‹çš„ä¸Šå¸‚æ¸…å–® APIï¼ˆè‹¥å¤±æ•ˆå°±å¿½ç•¥ï¼‰
        url = "https://isin.twse.com.tw/isin/C_public.jsp?strMode=2"
        r = _requests_get(url, timeout=15)
        r.raise_for_status()
        tables = pd.read_html(r.text)
        if not tables:
            return out
        t = tables[0]
        # ç¬¬ä¸€æ¬„é€šå¸¸æ˜¯ã€Œæœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±ã€
        col0 = t.columns[0]
        for v in t[col0].astype(str).tolist():
            if len(v) < 6:
                continue
            # e.g. "2330ã€€å°ç©é›»"
            parts = [p for p in v.replace("\u3000", " ").split(" ") if p.strip()]
            if len(parts) >= 2 and parts[0].isdigit():
                code = parts[0].strip()
                name = parts[1].strip()
                out[f"{code}.TW"] = name
    except Exception:
        return out
    return out


# -----------------------------
# å¤§ç›¤æŒ‡æ•¸/åœ‹éš›ï¼šç›¤å‰=æ˜¨æ—¥æ”¶ç›¤ï¼Œç›¤ä¸­=å³æ™‚
# -----------------------------
@dataclass
class IndexSnapshot:
    symbol: str
    last: float
    prev_close: float
    change: float
    change_pct: float
    asof: str


def fetch_index_snapshot(symbol: str, session: str) -> Optional[IndexSnapshot]:
    """
    session:
      - PREMARKET: æŠ“ 1d æ”¶ç›¤
      - INTRADAY: æŠ“ 5m æœ€å¾Œä¸€ç­† + æ˜¨æ”¶
      - POSTMARKET: æŠ“ 1d æ”¶ç›¤
    """
    try:
        if session == "INTRADAY":
            intr = yf.download(symbol, period="2d", interval="5m", progress=False)
            d1 = yf.download(symbol, period="5d", interval="1d", progress=False)
            if intr is None or intr.empty or d1 is None or d1.empty:
                return None
            last = float(intr["Close"].dropna().iloc[-1])
            prev_close = float(d1["Close"].dropna().iloc[-2]) if len(d1) >= 2 else float(d1["Close"].iloc[-1])
            ts = intr.index[-1].to_pydatetime()
            asof = ts.strftime("%Y-%m-%d %H:%M")
        else:
            d1 = yf.download(symbol, period="10d", interval="1d", progress=False)
            if d1 is None or d1.empty:
                return None
            last = float(d1["Close"].dropna().iloc[-1])
            prev_close = float(d1["Close"].dropna().iloc[-2]) if len(d1) >= 2 else last
            ts = d1.index[-1].to_pydatetime()
            asof = ts.strftime("%Y-%m-%d")
        change = last - prev_close
        change_pct = (change / prev_close) * 100 if prev_close else 0.0
        return IndexSnapshot(symbol=symbol, last=last, prev_close=prev_close, change=change, change_pct=change_pct, asof=asof)
    except Exception:
        return None


# -----------------------------
# Regime è¨ˆç®—ï¼ˆV16.2ï¼‰
# -----------------------------
def compute_regime_metrics() -> dict:
    """
    ç”¨ ^TWII + ^VIXï¼š
    - MA200
    - SMR
    - SMR_MA5, Slope5
    - drawdown_pctï¼ˆ250æ—¥é«˜é»å›æ’¤ï¼‰
    - consolidation: 15æ—¥æ³¢å‹• < 5%
    """
    out = {
        "SMR": None,
        "MA200": None,
        "SMR_MA5": None,
        "Slope5": None,
        "VIX": None,
        "drawdown_pct": None,
        "consolidation_15d_vol": None,
        "consolidation_flag": False,
    }

    tw = yf.download("^TWII", period="400d", interval="1d", progress=False)
    vx = yf.download("^VIX", period="60d", interval="1d", progress=False)

    if tw is None or tw.empty or len(tw) < 220:
        return out

    close = tw["Close"].dropna()
    ma200 = float(close.rolling(200).mean().iloc[-1])
    last = float(close.iloc[-1])
    smr = (last - ma200) / ma200 if ma200 else 0.0

    smr_series = (close - close.rolling(200).mean()) / close.rolling(200).mean()
    smr_ma5 = float(smr_series.rolling(5).mean().dropna().iloc[-1])
    smr_ma5_prev = float(smr_series.rolling(5).mean().dropna().iloc[-2]) if len(smr_series.dropna()) >= 2 else smr_ma5
    slope5 = smr_ma5 - smr_ma5_prev

    # drawdown over 250 trading days
    lookback = close.iloc[-250:] if len(close) >= 250 else close
    peak = float(lookback.max())
    dd = (last - peak) / peak * 100 if peak else 0.0

    # consolidation: 15d price range <5%
    lb15 = close.iloc[-15:] if len(close) >= 15 else close
    if len(lb15) >= 10:
        vol15 = (float(lb15.max()) - float(lb15.min())) / float(lb15.mean()) * 100
    else:
        vol15 = None
    consolidation_flag = (vol15 is not None) and (vol15 < 5.0) and (0.08 <= smr <= 0.18)

    vix = float(vx["Close"].dropna().iloc[-1]) if (vx is not None and not vx.empty) else None

    out.update({
        "SMR": round(smr, 6),
        "MA200": round(ma200, 2),
        "SMR_MA5": round(smr_ma5, 6),
        "Slope5": round(slope5, 6),
        "VIX": round(vix, 2) if vix is not None else None,
        "drawdown_pct": round(dd, 2),
        "consolidation_15d_vol": round(vol15, 2) if vol15 is not None else None,
        "consolidation_flag": bool(consolidation_flag),
    })
    return out


def pick_regime(metrics: dict) -> Tuple[str, float]:
    """
    V16.2 å„ªå…ˆåºï¼š
    CRASH > HIBERNATION > MEAN_REVERSION > OVERHEAT > CONSOLIDATION > NORMAL
    """
    smr = metrics.get("SMR")
    slope5 = metrics.get("Slope5")
    vix = metrics.get("VIX")
    dd = metrics.get("drawdown_pct")
    cons = bool(metrics.get("consolidation_flag"))

    # max equity by regime (V16.2)
    max_equity_map = {
        "CRASH_RISK": 10.0,
        "HIBERNATION": 20.0,
        "MEAN_REVERSION": 45.0,
        "OVERHEAT": 55.0,
        "CONSOLIDATION": 65.0,
        "NORMAL": 85.0,
    }

    # ç¼ºè³‡æ–™ï¼šä¿å®ˆè½ NORMAL ä½†æœƒè¢« Data Health Gate æ“‹ä½ BUY/TRIAL
    if smr is None or slope5 is None:
        return "NORMAL", max_equity_map["NORMAL"]

    # CRASHï¼šVIX>35 æˆ–å›æ’¤>=18%
    if (vix is not None and vix > 35) or (dd is not None and abs(dd) >= 18 and dd < 0):
        return "CRASH_RISK", max_equity_map["CRASH_RISK"]

    # HIBERNATIONï¼šæ­¤è™•éœ€ MA14_Monthlyï¼ˆä½ è¦å‰‡ï¼‰ï¼Œå…è²»ç‰ˆç”¨è¿‘ 14 å€‹ã€Œæœˆæ”¶ç›¤ã€å¾ˆé›£æº–ç¢º
    # â†’ å…ˆä»¥è¿‘ 280 äº¤æ˜“æ—¥ç´„ 14 å€‹æœˆçš„æœˆç·šè¿‘ä¼¼ï¼Œé¿å…å‡è¨Šè™Ÿ
    # è‹¥ä½ ä¹‹å¾Œè¦ã€ŒçœŸ MA14_Monthlyï¼ˆæ¯æœˆæ”¶ç›¤ï¼‰ã€æˆ‘å¯ä»¥å†å¹«ä½ å‡ç´šè³‡æ–™çµæ§‹ã€‚
    # é€™è£¡å…ˆä¸è§¸ç™¼ï¼ˆé¿å…éŒ¯æ®ºï¼‰ã€‚
    # if ...: return "HIBERNATION", 20.0

    # MEAN_REVERSIONï¼šSMR 0.15-0.25 ä¸” slope5 < -0.0001
    if 0.15 <= smr <= 0.25 and slope5 < -0.0001:
        return "MEAN_REVERSION", max_equity_map["MEAN_REVERSION"]

    # OVERHEATï¼šSMR > 0.25
    if smr > 0.25:
        return "OVERHEAT", max_equity_map["OVERHEAT"]

    # CONSOLIDATION
    if cons:
        return "CONSOLIDATION", max_equity_map["CONSOLIDATION"]

    return "NORMAL", max_equity_map["NORMAL"]


def vix_stop_pct(vix: Optional[float]) -> float:
    """
    å‹•æ…‹åœæï¼ˆV16.2ï¼‰ï¼š
      VIX<20: -6%
      20-30: -8%
      >30: -10%
    """
    if vix is None:
        return 0.08
    if vix < 20:
        return 0.06
    if vix <= 30:
        return 0.08
    return 0.10


# -----------------------------
# æ³•äººï¼šTWSE T86ï¼ˆå¤–è³‡/æŠ•ä¿¡/è‡ªç‡Ÿå•†ï¼‰
# -----------------------------
def twse_date_fmt(yyyy_mm_dd: str) -> str:
    # TWSE API å¸¸ç”¨ YYYYMMDD
    return yyyy_mm_dd.replace("-", "")


def fetch_twse_t86_for_date(yyyy_mm_dd: str) -> pd.DataFrame:
    """
    æŠ“æŸä¸€æ—¥çš„ T86ï¼ˆä¸‰å¤§æ³•äººè²·è³£è¶…ï¼‰ï¼š
    https://www.twse.com.tw/rwd/zh/fund/T86?date=YYYYMMDD&selectType=ALLBUT0999&response=json
    """
    url = f"https://www.twse.com.tw/rwd/zh/fund/T86?date={twse_date_fmt(yyyy_mm_dd)}&selectType=ALLBUT0999&response=json"
    r = _requests_get(url, timeout=15)
    r.raise_for_status()
    j = r.json()
    data = j.get("data", [])
    fields = j.get("fields", [])
    if not data or not fields:
        return pd.DataFrame()

    df = pd.DataFrame(data, columns=fields)

    # æ¨™æº–åŒ–æ¬„ä½ï¼ˆä¸åŒæ™‚æœŸæ¬„åå¯èƒ½ç•¥æœ‰å·®ç•°ï¼Œåšå®¹éŒ¯ï¼‰
    # å¸¸è¦‹æ¬„ä½ï¼šè­‰åˆ¸ä»£è™Ÿã€è­‰åˆ¸åç¨±ã€å¤–é™¸è³‡è²·é€²è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)ã€å¤–é™¸è³‡è³£å‡ºè‚¡æ•¸ã€å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸ã€æŠ•ä¿¡è²·è³£è¶…è‚¡æ•¸
    def pick_col(keys: List[str]) -> Optional[str]:
        for k in keys:
            if k in df.columns:
                return k
        return None

    col_code = pick_col(["è­‰åˆ¸ä»£è™Ÿ"])
    col_name = pick_col(["è­‰åˆ¸åç¨±"])
    col_foreign_net = pick_col(["å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)", "å¤–è³‡è²·è³£è¶…è‚¡æ•¸", "å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸"])
    col_it_net = pick_col(["æŠ•ä¿¡è²·è³£è¶…è‚¡æ•¸"])

    if not col_code:
        return pd.DataFrame()

    def to_int(s) -> int:
        try:
            ss = str(s).replace(",", "").strip()
            if ss in ("", "--", "None", "nan"):
                return 0
            return int(float(ss))
        except Exception:
            return 0

    out = pd.DataFrame({
        "code": df[col_code].astype(str).str.strip(),
        "name": df[col_name].astype(str).str.strip() if col_name else "",
        "foreign_net": df[col_foreign_net].apply(to_int) if col_foreign_net else 0,
        "it_net": df[col_it_net].apply(to_int) if col_it_net else 0,
    })
    # åªç•™æ•¸å­—ä»£ç¢¼
    out = out[out["code"].str.match(r"^\d{4}$")]
    return out.reset_index(drop=True)


def build_institutional_panel(last_trade_date: str, lookback_days: int = 7) -> Tuple[pd.DataFrame, List[str]]:
    """
    å›å‚³ panelï¼š
      index=code, columns=[d0..d4] foreign_net/it_net
    """
    warnings = []
    dates = []
    dt = datetime.strptime(last_trade_date, "%Y-%m-%d").date()
    # å¾€å‰æŠ“ 7 å¤©æ—¥æ›†ï¼Œé€šå¸¸èƒ½æ¶µè“‹ 5 å€‹äº¤æ˜“æ—¥
    for i in range(lookback_days):
        dates.append((dt - timedelta(days=i)).strftime("%Y-%m-%d"))
    dates = list(reversed(dates))

    daily = []
    for d in dates:
        try:
            df = fetch_twse_t86_for_date(d)
            if df.empty:
                continue
            df["date"] = d
            daily.append(df)
        except Exception as e:
            warnings.append(f"T86_FAIL:{d}:{type(e).__name__}")
            continue

    if not daily:
        return pd.DataFrame(), warnings

    all_df = pd.concat(daily, ignore_index=True)
    # å–æœ€è¿‘ 5 å€‹æœ‰è³‡æ–™çš„äº¤æ˜“æ—¥
    avail_dates = sorted(all_df["date"].unique().tolist())
    last5 = avail_dates[-5:] if len(avail_dates) >= 5 else avail_dates

    panel = all_df[all_df["date"].isin(last5)].copy()
    return panel, warnings


def inst_metrics_for_symbol(panel: pd.DataFrame, symbol_tw: str) -> dict:
    """
    symbol_tw: '2330.TW'
    å›å‚³ï¼š
      inst_streak3, inst_streak5, inst_dir3, foreign_dir
    """
    out = {
        "inst_streak3": 0,
        "inst_streak5": 0,
        "inst_dir3": "MISSING",
        "foreign_dir": "MISSING",
        "inst_status": "UNAVAILABLE",
        "inst_dates_5": [],
    }
    if panel is None or panel.empty:
        return out

    code = symbol_tw.replace(".TW", "")
    df = panel[panel["code"] == code].copy()
    if df.empty:
        return out

    # ä»¥ã€Œå¤–è³‡+æŠ•ä¿¡ã€ä½œç‚ºæ³•äººç¸½å’Œï¼ˆä½ å¯æ”¹æˆåªçœ‹æŠ•ä¿¡/æˆ–åŠ è‡ªç‡Ÿï¼‰
    df["inst_net"] = df["foreign_net"].astype(int) + df["it_net"].astype(int)
    df = df.sort_values("date")
    dates = df["date"].tolist()
    inst = df["inst_net"].tolist()
    foreign = df["foreign_net"].tolist()

    out["inst_dates_5"] = dates[-5:]

    # inst_dir3ï¼šè¿‘ä¸‰æ—¥åˆè¨ˆæ­£è² 
    last3 = inst[-3:] if len(inst) >= 3 else inst
    s3 = int(np.sum(last3)) if last3 else 0
    if len(last3) >= 3:
        out["inst_dir3"] = "POSITIVE" if s3 > 0 else ("NEGATIVE" if s3 < 0 else "NEUTRAL")
    else:
        out["inst_dir3"] = "MISSING"

    # foreign_dirï¼šè¿‘ä¸‰æ—¥å¤–è³‡åˆè¨ˆ
    f3 = foreign[-3:] if len(foreign) >= 3 else foreign
    sf3 = int(np.sum(f3)) if f3 else 0
    if len(f3) >= 3:
        out["foreign_dir"] = "POSITIVE" if sf3 > 0 else ("NEGATIVE" if sf3 < 0 else "NEUTRAL")
    else:
        out["foreign_dir"] = "MISSING"

    # streak3 / streak5ï¼šé€£çºŒæ—¥ inst_net>0
    def streak(xs: List[int]) -> int:
        c = 0
        for v in reversed(xs):
            if v > 0:
                c += 1
            else:
                break
        return c

    out["inst_streak3"] = min(streak(inst), 3)
    out["inst_streak5"] = min(streak(inst), 5)

    # inst_statusï¼šè‡³å°‘æœ‰ 3 æ—¥è³‡æ–™å°±è¦–ç‚º READYï¼ˆä½ å¯åŠ æ›´åš´æ ¼é–€æª»ï¼‰
    out["inst_status"] = "READY" if len(inst) >= 3 else "UNAVAILABLE"
    return out


# -----------------------------
# å€‹è‚¡æŠ€è¡“è³‡æ–™ï¼ˆå…è²»ï¼šyfinanceï¼‰
# -----------------------------
def fetch_stock_daily(tickers: List[str]) -> pd.DataFrame:
    data = yf.download(tickers, period="260d", interval="1d", progress=False, group_by="ticker", auto_adjust=False)
    return data


def stock_features(data: pd.DataFrame, symbol: str) -> dict:
    """
    å›å‚³ï¼š
      Price, MA20, MA60, MA200, MA_Bias(%), Vol_Ratio(ç•¶æ—¥é‡/20æ—¥å‡é‡), Score(ç°¡æ˜“)
    """
    out = {
        "Price": None,
        "MA_Bias": 0.0,
        "Vol_Ratio": None,
        "Score": 0.0,
        "Body_Power": 0.0,
        "Tag": "â—‹è§€å¯Ÿ(è§€æœ›)",
    }

    try:
        if isinstance(data.columns, pd.MultiIndex):
            df = data[symbol].copy()
        else:
            df = data.copy()

        close = df["Close"].dropna()
        vol = df["Volume"].dropna()

        if close.empty:
            return out

        price = float(close.iloc[-1])
        ma20 = float(close.rolling(20).mean().iloc[-1]) if len(close) >= 20 else float(close.mean())
        ma60 = float(close.rolling(60).mean().iloc[-1]) if len(close) >= 60 else ma20
        ma200 = float(close.rolling(200).mean().iloc[-1]) if len(close) >= 200 else ma60

        bias = (price - ma20) / ma20 * 100 if ma20 else 0.0
        vr = None
        if len(vol) >= 20:
            vr = float(vol.iloc[-1]) / float(vol.rolling(20).mean().iloc[-1]) if float(vol.rolling(20).mean().iloc[-1]) else None

        # Scoreï¼šå…è²»æ¨¡æ“¬ç”¨ï¼ˆä½ å¯æ›æˆä½ æ—¢æœ‰çš„ analyzer æ‰“åˆ†ï¼‰
        # è¶¨å‹¢ï¼šprice>ma20>ma60 +10ï¼›price>ma200 +10ï¼›bias æ­£ +10ï¼›vol_ratio>1 +10
        score = 0.0
        if price > ma20 > ma60:
            score += 10
        if price > ma200:
            score += 10
        if bias > 0:
            score += 10
        if vr is not None and vr > 1.0:
            score += 10

        # æ¨™ç±¤ï¼ˆç¤ºæ„ï¼‰
        tag = "â—‹è§€å¯Ÿ(è§€æœ›)"
        if score >= 30 and bias > 0:
            tag = "ğŸŸ¢èµ·æ¼²(è§€æœ›)"
        if vr is not None and vr >= 1.5:
            tag = "ğŸ”¥ä¸»åŠ›(è§€æœ›)"

        out.update({
            "Price": round(price, 4),
            "MA_Bias": round(bias, 2),
            "Vol_Ratio": round(vr, 4) if vr is not None else None,
            "Score": round(score, 1),
            "Tag": tag,
        })
        return out
    except Exception:
        return out


# -----------------------------
# Top20ï¼šå…è²»/æ¨¡æ“¬æœŸçš„ã€Œå‹•æ…‹æƒæã€ç­–ç•¥
# -----------------------------
def build_universe(positions: List[dict]) -> List[str]:
    s = set(DEFAULT_UNIVERSE)
    for p in positions or []:
        sym = str(p.get("symbol", "")).strip()
        if sym:
            s.add(sym)
    return sorted(s)


def rank_top20(features_map: Dict[str, dict], inst_map: Dict[str, dict]) -> List[str]:
    """
    æ’åï¼šç”¨ Score +ï¼ˆæ³•äººåŠ æ¬Šï¼‰+ï¼ˆé‡èƒ½åŠ æ¬Šï¼‰
    ç›®çš„ï¼šæ¯å¤©èƒ½æ›´æ–°å‡ºã€Œå¸‚å ´å¼·å‹¢æ—ç¾¤ã€è¿‘ä¼¼ Top20ï¼ˆå…è²»å¯è·‘ã€å¯è§£é‡‹ã€å¯ç¨½æ ¸ï¼‰
    """
    rows = []
    for sym, f in features_map.items():
        score = float(f.get("Score") or 0.0)
        vr = f.get("Vol_Ratio")
        vr_bonus = 0.0
        if vr is not None:
            vr_bonus = min(10.0, max(0.0, (float(vr) - 0.8) * 10.0))  # 0.8â†’0, 1.8â†’10

        im = inst_map.get(sym, {})
        # æ³•äººåŠ åˆ†ï¼šstreak3 + dir3
        inst_bonus = 0.0
        if im.get("inst_status") == "READY":
            inst_bonus += float(im.get("inst_streak3", 0)) * 2.0  # 0~6
            if im.get("inst_dir3") == "POSITIVE":
                inst_bonus += 4.0

        total = score + vr_bonus + inst_bonus
        rows.append((sym, total))

    rows.sort(key=lambda x: x[1], reverse=True)
    top = [r[0] for r in rows[:20]]
    return top


# -----------------------------
# Layer åˆ¤å®šï¼ˆå« A+ï¼‰
# -----------------------------
def classify_layer(regime: str, momentum_lock: bool, vol_ratio: Optional[float], inst: dict) -> str:
    """
    A+ï¼šinst_streak5>=5 ä¸” foreign_dir=POSITIVE
    A ï¼šinst_streak3>=3 ä¸” inst_dir3=POSITIVE
    B ï¼š(regime in OVERHEAT/CONSOLIDATION) ä¸” momentum_lock=True ä¸” vol_ratio>0.8
    NONEï¼šå…¶ä»–
    """
    if inst.get("inst_streak5", 0) >= 5 and inst.get("foreign_dir") == "POSITIVE":
        return "A+"
    if inst.get("inst_streak3", 0) >= 3 and inst.get("inst_dir3") == "POSITIVE":
        return "A"
    if regime in ("OVERHEAT", "CONSOLIDATION"):
        if momentum_lock and (vol_ratio is not None) and float(vol_ratio) > 0.8:
            return "B"
    return "NONE"


def compute_momentum_lock(features_map: Dict[str, dict]) -> bool:
    """
    å…è²»ç‰ˆå…ˆç”¨ç°¡åŒ–ï¼šTop20 ä¸­ã€ŒScore>=30ã€å æ¯”>50% è¦–ç‚º momentum_lock
    ï¼ˆä½ è‹¥å·²æœ‰ SMR slope é€£å››æ—¥é‚è¼¯ï¼Œä¹‹å¾Œå¯æ›¿æ›ï¼‰
    """
    if not features_map:
        return False
    scores = [float(v.get("Score") or 0.0) for v in features_map.values()]
    if not scores:
        return False
    strong = sum(1 for s in scores if s >= 30.0)
    return (strong / len(scores)) >= 0.5


# -----------------------------
# å¸³æˆ¶ï¼šå…è²»æ¨¡æ“¬ï¼ˆå¯ç”¨ configs/account.jsonï¼‰
# -----------------------------
def load_account() -> dict:
    """
    ä½ å¯ä»¥åœ¨ repo æ”¾ configs/account.jsonï¼Œä¾‹å¦‚ï¼š
    {
      "cash_balance": 2000000,
      "total_equity": 2000000,
      "positions": []
    }
    """
    path = "configs/account.json"
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception:
            pass
    return {
        "cash_balance": 2000000,
        "total_equity": 2000000,
        "positions": [],
    }


# -----------------------------
# Data Health Gateï¼ˆä½ è¦çš„ã€Œçµ•å°é˜²ç·šã€ï¼‰
# -----------------------------
def data_health_gate(trade_date: str, inst_ready_any: bool, amount_ok: bool, stale_flag: bool) -> Tuple[bool, str]:
    """
    degraded_mode=true if:
      - staleï¼ˆæ—¥æœŸè½å¾Œï¼‰
      - amount_total ç„¡æ³•å–å¾—
      - æ³•äººè³‡æ–™å®Œå…¨ä¸å¯ç”¨
    """
    reasons = []
    if stale_flag:
        reasons.append("DATA_STALE")
    if not amount_ok:
        reasons.append("AMOUNT_UNAVAILABLE")
    if not inst_ready_any:
        reasons.append("INST_UNAVAILABLE")

    degraded = len(reasons) > 0
    comment = "; ".join(reasons) if reasons else "OK"
    return degraded, comment


# -----------------------------
# ä¸»æµç¨‹ï¼šç”¢å‡º Arbiter Input JSON
# -----------------------------
def build_arbiter_input(session: str = "PREMARKET") -> dict:
    now = _now_taipei()
    ts_str = now.strftime("%Y-%m-%d %H:%M")

    trade_date = get_last_trade_date()
    stale_flag = is_stale(trade_date, max_lag_trading_days=1)

    account = load_account()
    positions = account.get("positions", [])

    # 1) å¤§ç›¤èˆ‡åœ‹éš›ï¼ˆç›¤å‰è¦çœ‹åˆ°æ˜¨æ—¥ï¼‰
    twii = fetch_index_snapshot("^TWII", session if session != "PREMARKET" else "POSTMARKET")
    spx = fetch_index_snapshot("^GSPC", "POSTMARKET")  # ç›¤å‰çœ‹ç¾è‚¡æ˜¨æ”¶
    ixic = fetch_index_snapshot("^IXIC", "POSTMARKET")
    dji = fetch_index_snapshot("^DJI", "POSTMARKET")
    vix = fetch_index_snapshot("^VIX", "POSTMARKET")

    # 2) æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆï¼‰
    amount_ok = True
    amount_twse = None
    amount_tpex = None
    amount_total = None
    amount_sources = {"twse": None, "tpex": None, "error": None}
    try:
        ma = fetch_amount_total()
        amount_twse = int(ma.amount_twse)
        amount_tpex = int(ma.amount_tpex)
        amount_total = int(ma.amount_total)
        amount_sources["twse"] = ma.source_twse
        amount_sources["tpex"] = ma.source_tpex
    except Exception as e:
        amount_ok = False
        amount_sources["error"] = f"{type(e).__name__}: {str(e)[:160]}"

    # 3) Regime
    regime_metrics = compute_regime_metrics()
    regime, max_equity_allowed_pct = pick_regime(regime_metrics)

    # 4) æ³•äºº panelï¼ˆT86ï¼‰
    panel, inst_warn = build_institutional_panel(trade_date, lookback_days=7)

    # 5) åç¨±å°ç…§
    name_map = fetch_twse_stock_names()

    # 6) Universe + å€‹è‚¡æŠ€è¡“
    universe = build_universe(positions)
    data = fetch_stock_daily(universe)

    features_map: Dict[str, dict] = {}
    inst_map: Dict[str, dict] = {}

    inst_ready_any = False

    for sym in universe:
        f = stock_features(data, sym)
        features_map[sym] = f

        im = inst_metrics_for_symbol(panel, sym)
        inst_map[sym] = im
        if im.get("inst_status") == "READY":
            inst_ready_any = True

    # 7) Top20ï¼ˆæ¯æ—¥æ›´æ–°ï¼‰
    top20 = rank_top20(features_map, inst_map)

    # 8) momentum_lockï¼ˆç°¡åŒ–ç‰ˆï¼‰
    top20_features = {s: features_map[s] for s in top20 if s in features_map}
    momentum_lock = compute_momentum_lock(top20_features)

    # 9) Data Health Gate â†’ degraded_mode
    degraded_mode, gate_comment = data_health_gate(
        trade_date=trade_date,
        inst_ready_any=inst_ready_any,
        amount_ok=amount_ok,
        stale_flag=stale_flag,
    )

    # 10) çµ„ stocksï¼ˆTop20 + æŒå€‰è£œå…¥ï¼Œé¿å…ã€Œè²·äº†å°ç©é›»éš”å¤©æ‰å‡ºå°±ä¸åˆ†æã€ï¼‰
    tracked = list(dict.fromkeys(top20 + [p.get("symbol") for p in positions if p.get("symbol")]))

    stocks_out = []
    for i, sym in enumerate(tracked, start=1):
        f = features_map.get(sym, {})
        im = inst_map.get(sym, {})
        name = name_map.get(sym, sym.replace(".TW", ""))

        tier = "A" if i <= 10 else "B"
        top20_flag = sym in top20
        orphan_holding = (not top20_flag) and any(str(p.get("symbol")) == sym for p in positions)

        layer = classify_layer(
            regime=regime,
            momentum_lock=momentum_lock,
            vol_ratio=f.get("Vol_Ratio"),
            inst=im,
        )

        stocks_out.append({
            "Symbol": sym,
            "Name": name,
            "Price": f.get("Price"),
            "ranking": {
                "symbol": sym,
                "rank": i,
                "tier": tier,
                "top20_flag": bool(top20_flag),
                "topn_actual": len(top20),
            },
            "Technical": {
                "MA_Bias": f.get("MA_Bias", 0.0),
                "Vol_Ratio": f.get("Vol_Ratio"),
                "Body_Power": f.get("Body_Power", 0.0),
                "Score": f.get("Score", 0.0),
                "Tag": f.get("Tag", "â—‹è§€å¯Ÿ(è§€æœ›)"),
            },
            "Institutional": {
                "Inst_Status": im.get("inst_status", "UNAVAILABLE"),
                "Inst_Streak3": int(im.get("inst_streak3", 0)),
                "Inst_Streak5": int(im.get("inst_streak5", 0)),
                "Inst_Dir3": im.get("inst_dir3", "MISSING"),
                "Foreign_Dir": im.get("foreign_dir", "MISSING"),
                "Inst_Dates_5": im.get("inst_dates_5", []),
                "Layer": layer,  # <<<<<< A+ / A / B / NONE
            },
            "Structure": {
                "OPM": 0.0,
                "Rev_Growth": 0.0,
                "PE": 0.0,
                "Sector": "Unknown",
            },
            "risk": {
                "position_pct_max": 12,
                "risk_per_trade_max": 1.0,
                "trial_flag": True,
            },
            "orphan_holding": bool(orphan_holding),
            "weaken_flags": {
                "technical_weaken": False,
                "structure_weaken": False,
            }
        })

    # 11) macro.overviewï¼ˆç›¤å‰/ç›¤ä¸­/ç›¤å¾ŒæŒ‡æ•¸ï¼‰
    indices = []
    def add_idx(snap: Optional[IndexSnapshot], name: str):
        if not snap:
            return
        indices.append({
            "symbol": snap.symbol,
            "name": name,
            "last": round(snap.last, 2),
            "prev_close": round(snap.prev_close, 2),
            "change": round(snap.change, 2),
            "change_pct": round(snap.change_pct, 3),
            "asof": snap.asof,
        })

    add_idx(twii, "TAIEX")
    add_idx(spx, "S&P 500")
    add_idx(ixic, "NASDAQ")
    add_idx(dji, "DJIA")
    add_idx(vix, "VIX")

    # 12) æˆäº¤é‡æ­£è¦åŒ–ï¼ˆç›¤ä¸­ç”¨ï¼‰
    norm = {"progress": None, "amount_norm_cum_ratio": None, "amount_norm_slice_ratio": None, "amount_norm_label": "UNKNOWN"}
    if amount_total is not None:
        # å…è²»ç‰ˆæ²’æœ‰ã€Œ20æ—¥æˆäº¤é‡‘é¡ä¸­ä½æ•¸ã€è³‡æ–™å€‰åº«ï¼Œå…ˆç”¨ Noneï¼ˆä½ è‹¥æœ‰ data/global_market_summary.csv å¯æ¥ä¸Šï¼‰
        # é€™è£¡ä¿ç•™æ¬„ä½ï¼Œé¿å… Arbiter schema æ–·è£‚
        norm = {"progress": None, "amount_norm_cum_ratio": None, "amount_norm_slice_ratio": None, "amount_norm_label": "UNKNOWN"}

    overview = {
        "amount_twse": amount_twse if amount_twse is not None else "UNAVAILABLE",
        "amount_tpex": amount_tpex if amount_tpex is not None else "UNAVAILABLE",
        "amount_total": amount_total if amount_total is not None else "UNAVAILABLE",
        "amount_sources": amount_sources,
        "avg20_amount_total_median": None,  # å…è²»ç‰ˆå…ˆç•™ç©ºï¼ˆè‹¥ä½ æœ‰å€‰åº«å¯è£œï¼‰
        "progress": norm.get("progress"),
        "amount_norm_cum_ratio": norm.get("amount_norm_cum_ratio"),
        "amount_norm_slice_ratio": norm.get("amount_norm_slice_ratio"),
        "amount_norm_label": norm.get("amount_norm_label", "UNKNOWN"),
        "trade_date": trade_date,
        "data_mode": session,
        "inst_status": "READY" if inst_ready_any else "UNAVAILABLE",
        "inst_dates_3d": [],  # è‹¥ä½ è¦å…¨å¸‚å ´æ³•äººæ—¥åºåˆ—å†è£œ
        "data_date_finmind": None,
        "kill_switch": False,
        "v14_watch": False,
        "degraded_mode": bool(degraded_mode),
        "market_comment": gate_comment,  # Arbiter æœƒå¿½ç•¥ market_commentï¼ˆä½ è¦å‰‡ï¼‰
        "regime": regime,
        "regime_metrics": regime_metrics,
        "max_equity_allowed_pct": float(max_equity_allowed_pct),
        "warnings": inst_warn,
    }

    payload = {
        "meta": {
            "system": SYSTEM_VERSION,
            "market": MARKET,
            "timestamp": ts_str,
            "session": session
        },
        "macro": {
            "overview": overview,
            "indices": indices
        },
        "account": account,
        "stocks": stocks_out
    }
    return payload


def main():
    # Streamlit/app.py æœƒå‘¼å« build_arbiter_inputï¼›é€™è£¡ä¿ç•™ CLI æ–¹ä¾¿ä½ æœ¬æ©Ÿæ¸¬
    session = os.getenv("SESSION", "PREMARKET").strip().upper()
    if session not in ("PREMARKET", "INTRADAY", "POSTMARKET"):
        session = "PREMARKET"
    payload = build_arbiter_input(session=session)
    print(json.dumps(payload, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

