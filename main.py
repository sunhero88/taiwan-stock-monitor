# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import datetime
import os
from pathlib import Path

# 1. é é¢é…ç½®
st.set_page_config(page_title="Predator æˆ°ç•¥æŒ‡æ®ä¸­å¿ƒ V14.0", page_icon="ğŸ¦…", layout="wide")

# å®šç¾©æ•¸æ“šè·¯å¾‘
root_dir = Path(__file__).parent.absolute()
data_file = root_dir / "global_market_summary.csv"

# 2. å´é‚Šæ¬„é¡¯ç¤º
st.sidebar.title("ğŸ¦… ç³»çµ±ç‹€æ…‹")
update_time = datetime.datetime.now().strftime('%H:%M:%S')
st.sidebar.success(f"ğŸ“¡ æ ¸å¿ƒå·²å°±ç·’\nç³»çµ±æ™‚é–“: {update_time}")

# 3. ä¸»æ¨™é¡Œ
st.title("ğŸ¦… å®‡å®™ç¬¬ä¸€è‚¡å¸‚æ™ºèƒ½åˆ†æç³»çµ± V14.0")
st.markdown("**è‡ªå‹•ä¿®å¾©é©…å‹•ç‰ˆ** | æ ¸å¿ƒé‚è¼¯ï¼šPredator V14.0")

# 4. æ ¸å¿ƒæ•¸æ“šå¼•æ“
def run_analysis_engine():
    images, df_res, text_reports = None, None, {}
    try:
        with st.status("æ­£åœ¨åŸ·è¡Œ Predator æ·±åº¦åˆ†æ...", expanded=True) as status:
            st.write("ğŸ“¡ å•Ÿå‹•åˆ†ææ¨¡çµ„...")
            import analyzer
            
            st.write("ğŸ” æŠ“å–å…¨çƒå¸‚å ´æ•¸æ“šä¸­ (é è¨ˆ 30-60 ç§’)...")
            results = analyzer.run('tw-share')
            
            # åš´æ ¼æ ¡å°å›å‚³çµæœ
            if results and isinstance(results, (list, tuple)) and len(results) >= 3:
                images = results[0]
                df_res = results[1]
                text_reports = results[2] if results[2] else {}
                status.update(label="âœ… å¯¦æ™‚æ•¸æ“šåˆ†æå®Œæˆï¼", state="complete")
            else:
                st.warning("âš ï¸ å¯¦æ™‚æŠ“å–æœªå›å‚³æœ‰æ•ˆæ•¸æ“šï¼Œå˜—è©¦åŠ è¼‰æ­·å²å­˜æª”...")
                if data_file.exists():
                    df_res = pd.read_csv(data_file)
                    text_reports = {"FINAL_AI_REPORT": "å¯¦æ™‚é€£æ¥ä¸ç©©å®šï¼Œç›®å‰é¡¯ç¤ºæœ€è¿‘ä¸€æ¬¡ç›¤å¾Œå‚™ä»½æ•¸æ“šã€‚"}
                    status.update(label="âš ï¸ ä½¿ç”¨å‚™ä»½æ•¸æ“šå‘ˆç¾", state="complete")
    except Exception as e:
        st.error(f"âŒ å¼•æ“é‹ä½œç•°å¸¸: {str(e)}")
        if data_file.exists():
            df_res = pd.read_csv(data_file)
            text_reports = {"FINAL_AI_REPORT": "å¼•æ“åˆå§‹åŒ–å¤±æ•—ï¼Œå·²è‡ªå‹•åˆ‡æ›è‡³æ­·å²æ•¸æ“šæ¨¡å¼ã€‚"}
    
    return images, df_res, text_reports

# 5. åŸ·è¡Œåˆ†æ
images, df_res, text_reports = run_analysis_engine()

# 6. æˆ°ç•¥åˆ¤è®€å‘ˆç¾
if (text_reports and len(text_reports) > 0) or df_res is not None:
    col1, col2 = st.columns([6, 4])
    
    with col1:
        st.subheader("ğŸ¤– Predator æ™ºèƒ½æˆ°ç•¥åˆ¤è®€")
        # ç¢ºä¿ ai_report æ°¸é æœ‰æ–‡å­—å…§å®¹
        ai_report = text_reports.get("FINAL_AI_REPORT", "åˆ†æå¼•æ“æ­£åœ¨è§£æç±Œç¢¼èˆ‡ä½éšæ•¸æ“š...")
        st.info(ai_report)
        
        # æº–å‚™çµ¦ AI çš„æ•¸æ“šå¿«ç…§
        copy_text = f"""ã€Predator æ•¸æ“šä»‹å…¥ã€‘
æ™‚é–“ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}
ç‹€æ…‹ï¼š{ai_report[:100]}..."""
        st.code(copy_text, language="markdown")
        
        if images and len(images) > 0:
            img_path = images[0].get("path", "")
            if os.path.exists(img_path):
                st.image(img_path, use_container_width=True)

    with col2:
        st.subheader("ğŸ¯ é—œéµç›£æ§æ¨™çš„ (TOP 10)")
        if df_res is not None:
            # å„²å­˜æœ¬æ¬¡æˆåŠŸçµæœ
            df_res.to_csv(data_file, index=False, encoding='utf-8-sig')
            
            # é¡¯ç¤ºè¡¨æ ¼
            cols = [c for c in ['Symbol', 'Close', 'Return', 'Vol_Ratio'] if c in df_res.columns]
            if cols:
                st.dataframe(
                    df_res[cols].head(10).style.format({
                        'Return': '{:+.2f}%', 'Vol_Ratio': '{:.2f}x'
                    } if 'Return' in df_res.columns else {}).background_gradient(cmap='RdYlGn'),
                    height=500
                )
else:
    st.error("ğŸš¨ åš´é‡éŒ¯èª¤ï¼šç„¡æ³•ç²å–å¯¦æ™‚æ•¸æ“šæˆ–æ­·å²å‚™ä»½ï¼Œè«‹æª¢æŸ¥ analyzer.py å®Œæ•´æ€§ã€‚")
