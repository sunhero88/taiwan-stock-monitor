# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import datetime
import os
from pathlib import Path

# 1. é é¢é…ç½®
st.set_page_config(page_title="Predator æˆ°ç•¥æŒ‡æ®ä¸­å¿ƒ V14.0", page_icon="ğŸ¦…", layout="wide")

# å®šç¾©æ•¸æ“šè·¯å¾‘
root_dir = Path(__file__).parent.absolute()
data_file = root_dir / "global_market_summary.csv"

# 2. å´é‚Šæ¬„é¡¯ç¤º
st.sidebar.title("ğŸ¦… ç³»çµ±ç‹€æ…‹")
st.sidebar.success(f"ğŸ“¡ æ ¸å¿ƒå·²å°±ç·’\nç³»çµ±æ™‚é–“: {datetime.datetime.now().strftime('%H:%M:%S')}")

# 3. ä¸»æ¨™é¡Œ
st.title("ğŸ¦… å®‡å®™ç¬¬ä¸€è‚¡å¸‚æ™ºèƒ½åˆ†æç³»çµ± V14.0")
st.markdown("**çµ‚æ¥µå…¼å®¹é©…å‹•ç‰ˆ** | æ ¸å¿ƒé‚è¼¯ï¼šPredator V14.0")

# 4. æ ¸å¿ƒæ•¸æ“šå¼•æ“ (å¼·åŒ–é¡å‹æ ¡é©—)
def run_analysis_engine():
    images, df_res, text_reports = None, None, {}
    try:
        with st.status("æ­£åœ¨åŸ·è¡Œ Predator æ·±åº¦åˆ†æ...", expanded=True) as status:
            st.write("ğŸ“¡ å•Ÿå‹•åˆ†ææ¨¡çµ„...")
            import analyzer
            
            st.write("ğŸ” æŠ“å–å…¨çƒå¸‚å ´æ•¸æ“šä¸­ (é è¨ˆ 30-60 ç§’)...")
            results = analyzer.run('tw-share')
            
            # åš´æ ¼è§£åŒ…ä¸¦å¼·åˆ¶æ ¼å¼è½‰æ›
            if results and len(results) >= 3:
                images = results[0]
                df_res = results[1]
                
                # å¼·åˆ¶è½‰æ› text_reports ç‚ºå­—å…¸ï¼Œé˜²æ­¢ tuple å°è‡´çš„ .get() å ±éŒ¯
                raw_reports = results[2]
                if isinstance(raw_reports, dict):
                    text_reports = raw_reports
                elif isinstance(raw_reports, (list, tuple)):
                    # å¦‚æœå›å‚³æ˜¯åˆ—è¡¨æˆ–å…ƒçµ„ï¼Œå°‡å…¶è½‰æ›ç‚ºå¸¶æœ‰ç´¢å¼•çš„å­—å…¸æˆ–æå–ç¬¬ä¸€å€‹å…ƒç´ 
                    text_reports = {"FINAL_AI_REPORT": str(raw_reports[0]) if len(raw_reports) > 0 else ""}
                else:
                    text_reports = {"FINAL_AI_REPORT": str(raw_reports)}
                
                status.update(label="âœ… å¯¦æ™‚æ•¸æ“šåˆ†æå®Œæˆï¼", state="complete")
            else:
                st.warning("âš ï¸ åˆ†æçµæœæ ¼å¼ä¸å®Œæ•´ï¼Œå˜—è©¦è®€å–å­˜æª”...")
    except Exception as e:
        st.error(f"âŒ å¼•æ“ç•°å¸¸: {str(e)}")
    
    # å‚™æ´é‚è¼¯ï¼šå¦‚æœåˆ†æå¤±æ•—ä½†æœ‰èˆŠæª”æ¡ˆ
    if df_res is None and data_file.exists():
        df_res = pd.read_csv(data_file)
        if not text_reports:
            text_reports = {"FINAL_AI_REPORT": "ç›®å‰é¡¯ç¤ºæœ€è¿‘ä¸€æ¬¡æˆåŠŸçš„ç›¤å¾Œå‚™ä»½æ•¸æ“šã€‚"}
            
    return images, df_res, text_reports

# 5. åŸ·è¡Œåˆ†æ
images, df_res, text_reports = run_analysis_engine()

# 6. æˆ°ç•¥åˆ¤è®€å‘ˆç¾
if df_res is not None or text_reports:
    col1, col2 = st.columns([6, 4])
    
    with col1:
        st.subheader("ğŸ¤– Predator æ™ºèƒ½æˆ°ç•¥åˆ¤è®€")
        # å®‰å…¨ç²å–å ±å‘Šå…§å®¹ï¼Œç¢ºä¿ text_reports æ˜¯å­—å…¸
        ai_report = text_reports.get("FINAL_AI_REPORT", "åˆ†æå¼•æ“æ­£åœ¨è¨ˆç®—ä¸­...") if isinstance(text_reports, dict) else str(text_reports)
        st.info(ai_report)
        
        # æ•¸æ“šä»‹å…¥å¿«ç…§
        st.code(f"ã€Predator æ•¸æ“šä»‹å…¥ã€‘\næ™‚é–“ï¼š{datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\nç³»çµ±å·²æ ¡æº–è‡³æœ€æ–°ç›¤å¾Œæ•¸æ“š", language="markdown")
        
        if images and len(images) > 0:
            img_path = images[0].get("path", "") if isinstance(images[0], dict) else ""
            if os.path.exists(img_path):
                st.image(img_path, use_container_width=True)

    with col2:
        st.subheader("ğŸ¯ é—œéµç›£æ§æ¨™æ¨™çš„ (TOP 10)")
        if df_res is not None:
            df_res.to_csv(data_file, index=False, encoding='utf-8-sig')
            show_cols = [c for c in ['Symbol', 'Close', 'Return', 'Vol_Ratio'] if c in df_res.columns]
            st.dataframe(df_res[show_cols].head(10).style.background_gradient(cmap='RdYlGn'), height=500)
else:
    st.error("ğŸš¨ ç„¡æ³•è¼‰å…¥æ•¸æ“šï¼Œè«‹ç¢ºèª analyzer.py æ˜¯å¦æ­£ç¢ºå›å‚³æ•¸æ“šåˆ—è¡¨ã€‚")
