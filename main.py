# main.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
import os
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Any, Optional, Tuple

import pandas as pd
import streamlit as st

from analyzer import run_analysis, generate_ai_json, SESSION_INTRADAY, SESSION_EOD
from finmind_institutional import fetch_finmind_institutional
from institutional_utils import calc_inst_3d

# ç›¤ä¸­/ç›¤å¾Œæˆäº¤é‡‘é¡ï¼ˆTWSE+TPEx åˆè¨ˆï¼‰
# ä½ å·²ç¶“æœ‰ market_amount.pyï¼ˆå« intraday_norm / fetch_amount_total ç­‰ï¼‰
from market_amount import (
    fetch_amount_total,
    intraday_norm,
)

# =========================
# åŸºæœ¬è¨­å®š
# =========================
TZ_TAIPEI = timezone(timedelta(hours=8))
ROOT = Path(__file__).resolve().parent
DATA_DIR = ROOT / "data"
DATA_DIR.mkdir(parents=True, exist_ok=True)

AMOUNT_HISTORY_CSV = DATA_DIR / "amount_history_tw.csv"           # æ—¥è³‡æ–™ï¼ˆEOD æˆ–ç›¤ä¸­å¿«ç…§éƒ½å¯è¨˜ï¼‰
AMOUNT_INTRADAY_CACHE = DATA_DIR / "amount_intraday_cache.json"   # ç›¤ä¸­åˆ‡ç‰‡ç”¨ï¼ˆå‰ä¸€æ¬¡å¿«ç…§ï¼‰

# =========================
# 0) èˆªé‹è‚¡ä¼°å€¼ï¼ˆæ‰‹å‹•è¦†è“‹å±¤ï¼‰
# =========================
SHIPPING_VALUATION = {
    "2603.TW": {
        "name_zh": "é•·æ¦®",
        "sector": "èˆªé‹",
        "opm_q": 22.73,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 41.92,
        "price_ref": 192.54,
        "price_ref_date": "2026-01-22",
        "pe_calc": 4.59,
        "label": "ğŸŸ¢ æ¥µåº¦ä½ä¼° (Deep Value)",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
    "2609.TW": {
        "name_zh": "é™½æ˜",
        "sector": "èˆªé‹",
        "opm_q": 10.49,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 7.83,
        "price_ref": 55.57,
        "price_ref_date": "2026-01-22",
        "pe_calc": 7.09,
        "label": "ğŸŸ¡",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
}


def _now_taipei() -> datetime:
    return datetime.now(tz=TZ_TAIPEI)


def _fmt_date(dt) -> str:
    try:
        return pd.to_datetime(dt).strftime("%Y-%m-%d")
    except Exception:
        return _now_taipei().strftime("%Y-%m-%d")


def _repo_paths_for_market_csv(market: str) -> list[Path]:
    """
    ä½  repo å·²ç¶“æŠŠæª”æ¡ˆé€æ­¥ç§»åˆ° data/ è³‡æ–™å¤¾ï¼Œå› æ­¤è¦åŒæ™‚æ”¯æ´ï¼š
    - data/data_tw-share.csvï¼ˆå„ªå…ˆï¼‰
    - data/data_tw.csv
    - æ ¹ç›®éŒ„ data_tw-share.csvï¼ˆç›¸å®¹èˆŠç‰ˆï¼‰
    - æ ¹ç›®éŒ„ data_tw.csv
    """
    fname = f"data_{market}.csv"
    return [
        DATA_DIR / fname,
        DATA_DIR / "data_tw-share.csv",
        DATA_DIR / "data_tw.csv",
        ROOT / fname,
        ROOT / "data_tw-share.csv",
        ROOT / "data_tw.csv",
    ]


def _load_market_csv(market: str) -> pd.DataFrame:
    candidates = _repo_paths_for_market_csv(market)
    for p in candidates:
        if p.exists():
            df = pd.read_csv(p)
            return df
    raise FileNotFoundError(
        "æ‰¾ä¸åˆ°å¸‚å ´è³‡æ–™æª”ã€‚å·²å˜—è©¦ï¼š\n" + "\n".join([str(p) for p in candidates])
    )


def _apply_shipping_valuation_overrides(df_top: pd.DataFrame) -> pd.DataFrame:
    """
    å°‡ SHIPPING_VALUATION ä»¥ Overlay å½¢å¼æ³¨å…¥ï¼Œä¸è¦†è“‹åŸæœ¬ Structure æ¬„ä½ã€‚
    """
    out = df_top.copy()

    def _inject(row: pd.Series) -> pd.Series:
        sym = str(row.get("Symbol", "")).strip()
        info = SHIPPING_VALUATION.get(sym)
        if not info:
            return row

        if not row.get("Name"):
            row["Name"] = info.get("name_zh", sym)

        row["Valuation_Override"] = {
            "sector": info.get("sector"),
            "opm_q": float(info.get("opm_q", 0.0)),
            "opm_q_period": info.get("opm_q_period"),
            "eps_ttm": float(info.get("eps_ttm", 0.0)),
            "price_ref": float(info.get("price_ref", 0.0)),
            "price_ref_date": info.get("price_ref_date"),
            "pe_calc": float(info.get("pe_calc", 0.0)),
            "label": info.get("label"),
            "source": info.get("source"),
        }
        return row

    out = out.apply(_inject, axis=1)
    return out


# =========================
# æˆäº¤é‡‘é¡ï¼šæ­·å²ä¸­ä½æ•¸ï¼ˆ20æ—¥ï¼‰
# =========================
def _read_amount_history() -> pd.DataFrame:
    if not AMOUNT_HISTORY_CSV.exists():
        return pd.DataFrame(columns=["date", "amount_twse", "amount_tpex", "amount_total"])
    try:
        df = pd.read_csv(AMOUNT_HISTORY_CSV)
        df["date"] = df["date"].astype(str)
        for c in ["amount_twse", "amount_tpex", "amount_total"]:
            df[c] = pd.to_numeric(df.get(c), errors="coerce").fillna(0).astype(int)
        return df
    except Exception:
        return pd.DataFrame(columns=["date", "amount_twse", "amount_tpex", "amount_total"])


def _append_amount_history(date_str: str, twse: int, tpex: int, total: int) -> None:
    df = _read_amount_history()
    # åŒä¸€å¤©åªä¿ç•™æœ€æ–°ä¸€ç­†
    df = df[df["date"] != date_str].copy()
    df = pd.concat(
        [
            df,
            pd.DataFrame(
                [{"date": date_str, "amount_twse": twse, "amount_tpex": tpex, "amount_total": total}]
            ),
        ],
        ignore_index=True,
    )
    df.to_csv(AMOUNT_HISTORY_CSV, index=False, encoding="utf-8")


def _avg20_median_amount_total() -> Optional[int]:
    df = _read_amount_history()
    if df.empty:
        return None
    last20 = df.sort_values("date").tail(20)
    if last20.empty:
        return None
    med = int(last20["amount_total"].median())
    return med if med > 0 else None


# =========================
# ç›¤ä¸­åˆ‡ç‰‡å¿«ç…§ï¼ˆä¿å®ˆå‹ç”¨ï¼‰
# =========================
@dataclass
class IntradayCache:
    ts_iso: str
    amount_total: int


def _load_intraday_cache() -> Optional[IntradayCache]:
    if not AMOUNT_INTRADAY_CACHE.exists():
        return None
    try:
        d = json.loads(AMOUNT_INTRADAY_CACHE.read_text(encoding="utf-8"))
        return IntradayCache(ts_iso=str(d.get("ts_iso")), amount_total=int(d.get("amount_total", 0)))
    except Exception:
        return None


def _save_intraday_cache(amount_total: int) -> None:
    payload = {"ts_iso": _now_taipei().isoformat(), "amount_total": int(amount_total)}
    AMOUNT_INTRADAY_CACHE.write_text(json.dumps(payload, ensure_ascii=False), encoding="utf-8")


def _prev_amount_for_slice(now: datetime) -> Optional[int]:
    """
    ä¿å®ˆå‹è¦çœ‹ã€Œåˆ‡ç‰‡é‡ã€ï¼šéœ€è¦å‰ä¸€ç­† amount_totalã€‚
    è‹¥å¿«ç…§å¤ªä¹…ï¼ˆ>30åˆ†é˜ï¼‰ï¼Œå°±ä¸æ‹¿ä¾†ç®—åˆ‡ç‰‡ï¼Œé¿å…åˆ‡ç‰‡å¤±çœŸã€‚
    """
    c = _load_intraday_cache()
    if not c:
        return None
    try:
        prev_ts = datetime.fromisoformat(c.ts_iso)
        age_min = (now - prev_ts).total_seconds() / 60.0
        if age_min <= 30:
            return int(c.amount_total)
        return None
    except Exception:
        return None


# =========================
# æ³•äººè³‡æ–™æ•´åˆï¼ˆFinMindï¼‰
# =========================
def _merge_institutional_into_df_top(df_top: pd.DataFrame, inst_df: pd.DataFrame, trade_date: str) -> pd.DataFrame:
    df_out = df_top.copy()
    inst_map: dict[str, dict[str, Any]] = {}

    for _, r in df_out.iterrows():
        symbol = str(r.get("Symbol", ""))
        inst_calc = calc_inst_3d(inst_df, symbol=symbol, trade_date=trade_date)

        inst_map[symbol] = {
            "Inst_Visual": inst_calc.get("Inst_Status", "PENDING"),
            "Inst_Net_3d": float(inst_calc.get("Inst_Net_3d", 0.0)),
            "Inst_Streak3": int(inst_calc.get("Inst_Streak3", 0)),
            "Inst_Dir3": inst_calc.get("Inst_Dir3", "PENDING"),
            "Inst_Status": inst_calc.get("Inst_Status", "PENDING"),
        }

    df_out["Institutional"] = df_out["Symbol"].astype(str).map(inst_map)
    return df_out


def _decide_inst_status_and_dates(inst_df: pd.DataFrame, symbols: list[str], trade_date: str) -> tuple[str, list[str]]:
    """
    V15.7 å®šç¾©ï¼š
    - READYï¼šè‡³å°‘æœ‰ä¸€æª”èƒ½ç®—å‡º Inst_Status=READYï¼ˆä»£è¡¨ä¸‰æ—¥è³‡æ–™é½Šï¼‰
    - PENDINGï¼šFinMind æœ‰å›è³‡æ–™ï¼Œä½†ä¸è¶³ä»¥é” READYï¼ˆå¸¸è¦‹ï¼šç›¤ä¸­/è³‡æ–™å°šæœªé½Šï¼‰
    - UNAVAILABLEï¼šæŠ“å–å¤±æ•—æˆ–ç©ºè³‡æ–™ï¼ˆAPI å¤±æ•ˆ/è¢«æ“‹/éŒ¯èª¤ï¼‰
    """
    if inst_df is None or inst_df.empty:
        return "UNAVAILABLE", []

    ready_any = False
    for sym in symbols:
        r = calc_inst_3d(inst_df, symbol=sym, trade_date=trade_date)
        if r.get("Inst_Status") == "READY":
            ready_any = True
            break

    # å–æœ€è¿‘ä¸‰å€‹äº¤æ˜“æ—¥ï¼ˆå°±ç®—ä¸æ˜¯é€£çºŒï¼Œä¹Ÿç”¨æ–¼è³‡è¨Šå‘ˆç¾ï¼‰
    dates_3d: list[str] = []
    try:
        if "date" in inst_df.columns:
            dates_3d = sorted(inst_df["date"].astype(str).unique().tolist())[-3:]
    except Exception:
        dates_3d = []

    return ("READY" if ready_any else "PENDING"), dates_3d


def _finmind_data_date(inst_df: pd.DataFrame) -> Optional[str]:
    try:
        if inst_df is None or inst_df.empty or "date" not in inst_df.columns:
            return None
        return str(pd.to_datetime(inst_df["date"], errors="coerce").max().date())
    except Exception:
        return None


# =========================
# V15.7ï¼šå¸‚å ´æ•˜è¿°ï¼ˆäººé¡ç”¨ï¼ŒArbiter å¿…é ˆå¿½ç•¥ï¼‰
# =========================
def generate_market_comment_retail(macro_overview: dict) -> str:
    """
    æ³¨æ„ï¼šé€™æ®µåªçµ¦äººé¡çœ‹ï¼›Arbiter å¿…é ˆå®Œå…¨å¿½ç•¥ market_commentï¼ˆä½ å·²åœ¨è¦å‰‡ä¸­æ˜ç¢ºè¦æ±‚ï¼‰ã€‚
    """
    kill_switch = bool(macro_overview.get("kill_switch", False))
    v14_watch = bool(macro_overview.get("v14_watch", False))
    degraded_mode = bool(macro_overview.get("degraded_mode", False))

    amount_total = macro_overview.get("amount_total", "å¾…æ›´æ–°")
    amount_norm_label = macro_overview.get("amount_norm_label", "UNKNOWN")

    inst_status = macro_overview.get("inst_status", "UNAVAILABLE")

    if kill_switch or v14_watch:
        return "ç³»çµ±é¢¨æ§å·²å•Ÿå‹•ï¼ˆç¦æ­¢é€²å ´ï¼‰ã€‚"

    # æˆäº¤é‡‘é¡å‘ˆç¾ï¼ˆå„„ï¼‰
    amt_text = "æˆäº¤é‡‘é¡å¾…æ›´æ–°"
    try:
        if isinstance(amount_total, str) and amount_total != "å¾…æ›´æ–°":
            amt = float(str(amount_total).replace(",", ""))
            amt_text = f"æˆäº¤é‡‘é¡ç´„ {amt/1e8:,.0f} å„„"
        elif isinstance(amount_total, (int, float)) and amount_total > 0:
            amt_text = f"æˆäº¤é‡‘é¡ç´„ {float(amount_total)/1e8:,.0f} å„„"
    except Exception:
        amt_text = "æˆäº¤é‡‘é¡å¾…æ›´æ–°"

    # é‡èƒ½æ¨™ç±¤ï¼ˆç›¤ä¸­æ­£è¦åŒ–å¾Œï¼‰
    vol_text = ""
    if amount_norm_label in ("LOW", "NORMAL", "HIGH"):
        vol_text = f"ï¼ˆé‡èƒ½æ­£è¦åŒ–ï¼š{amount_norm_label}ï¼‰"

    # æ³•äººç‹€æ…‹
    if inst_status == "READY":
        inst_text = "æ³•äººè³‡æ–™å¯ç”¨ã€‚"
    elif inst_status == "PENDING":
        inst_text = "æ³•äººè³‡æ–™æœªé½Šã€‚"
    else:
        inst_text = "æ³•äººè³‡æ–™ä¸å¯ç”¨ã€‚"

    # é™ç´šæ¨¡å¼
    if degraded_mode:
        strat = "è£æ±ºå±¤å·²é€²å…¥è³‡æ–™é™ç´šï¼šç¦æ­¢ BUY/TRIALã€‚"
    else:
        strat = "è£æ±ºå±¤å…è¨±æ­£å¸¸è©•ä¼°ï¼ˆä»ä»¥å€‹è‚¡æ¢ä»¶ç‚ºä¸»ï¼‰ã€‚"

    return f"{amt_text}{vol_text}ï¼›{inst_text}{strat}"


# =========================
# V15.7ï¼šç‹€æ…‹åˆ¤å®šå€å¡Šï¼ˆå¯ç›´æ¥è¦†è“‹ï¼‰
# =========================
def build_v15_7_status_block(
    session: str,
    trade_date: str,
    df_top_symbols: list[str],
) -> tuple[dict, pd.DataFrame]:
    """
    ç”¢å‡ºï¼š
    - macro_overviewï¼ˆå« inst_status / degraded_mode / amount_total ç­‰ï¼‰
    - inst_dfï¼ˆå€‹è‚¡æ³•äººåŸå§‹è³‡æ–™ï¼Œä¾›å¾ŒçºŒ mergeï¼‰
    """
    now = _now_taipei()

    # ---------- A) æˆäº¤é‡‘é¡ï¼ˆTWSE+TPEx åˆè¨ˆï¼‰ ----------
    amount_twse = "å¾…æ›´æ–°"
    amount_tpex = "å¾…æ›´æ–°"
    amount_total = "å¾…æ›´æ–°"
    amount_sources: dict[str, Any] = {"twse": None, "tpex": None, "error": None}

    try:
        amt = fetch_amount_total()  # MarketAmount
        amount_twse = f"{amt.amount_twse:,d}"
        amount_tpex = f"{amt.amount_tpex:,d}"
        amount_total = f"{amt.amount_total:,d}"
        amount_sources["twse"] = amt.source_twse
        amount_sources["tpex"] = amt.source_tpex

        # è¨˜éŒ„æ­·å²ï¼ˆä¸åˆ†ç›¤ä¸­/ç›¤å¾Œï¼›ç”¨ä¾†ä¼° 20 æ—¥ä¸­ä½æ•¸ï¼‰
        _append_amount_history(
            date_str=trade_date,
            twse=amt.amount_twse,
            tpex=amt.amount_tpex,
            total=amt.amount_total,
        )
    except Exception as e:
        amount_sources["error"] = f"{type(e).__name__}: {str(e)}"

    # 20æ—¥ä¸­ä½æ•¸ï¼ˆç”¨ amount_totalï¼‰
    avg20_median = _avg20_median_amount_total()
    avg20_amount_total_median = None if avg20_median is None else int(avg20_median)

    # ç›¤ä¸­æ­£è¦åŒ–ï¼ˆé¿å…å‹•ä¸å‹•å°± LOWï¼‰
    amount_norm = {
        "progress": None,
        "amount_norm_cum_ratio": None,
        "amount_norm_slice_ratio": None,
        "amount_norm_label": "UNKNOWN",
        "method_note": None,
    }

    # amount_total_nowï¼ˆintï¼‰æ‰ç®—å¾—å‡º norm
    amount_total_now_int: Optional[int] = None
    try:
        if isinstance(amount_total, str) and amount_total != "å¾…æ›´æ–°":
            amount_total_now_int = int(str(amount_total).replace(",", ""))
        elif isinstance(amount_total, (int, float)) and float(amount_total) > 0:
            amount_total_now_int = int(float(amount_total))
    except Exception:
        amount_total_now_int = None

    # ç›¤ä¸­ï¼šä¿å®ˆå‹çœ‹åˆ‡ç‰‡ã€ç©©å¥å‹çœ‹ç´¯ç©ã€è©¦æŠ•å‹å¿½ç•¥
    # é€™è£¡å…ˆæŠŠå…©å€‹ ratio éƒ½ç®—å‡ºä¾†ï¼Œè®“ Arbiterï¼ˆæˆ–äººé¡ï¼‰ä¾æƒ…å¢ƒå–ç”¨
    if session == SESSION_INTRADAY and amount_total_now_int is not None and avg20_median:
        prev = _prev_amount_for_slice(now)
        amount_norm = intraday_norm(
            amount_total_now=amount_total_now_int,
            amount_total_prev=prev,
            avg20_amount_total=avg20_median,
            now=now,
            alpha=0.65,
        )
        # æ›´æ–°å¿«ç…§ï¼Œä¾›ä¸‹ä¸€æ¬¡åˆ‡ç‰‡
        _save_intraday_cache(amount_total_now_int)

    # ---------- B) æ³•äººè³‡æ–™ ----------
    inst_df = pd.DataFrame(columns=["date", "symbol", "net_amount"])
    inst_fetch_error: Optional[str] = None

    # ç›¤ä¸­ä¹ŸæŠ“ï¼Œä½†æŠ“ä¸åˆ°å°± UNAVAILABLE
    start_date = (pd.to_datetime(trade_date) - pd.Timedelta(days=45)).strftime("%Y-%m-%d")
    end_date = trade_date

    try:
        inst_df = fetch_finmind_institutional(
            symbols=df_top_symbols,
            start_date=start_date,
            end_date=end_date,
            token=os.getenv("FINMIND_TOKEN", None),
        )
    except Exception as e:
        inst_fetch_error = f"{type(e).__name__}: {str(e)}"
        inst_df = pd.DataFrame(columns=["date", "symbol", "net_amount"])

    inst_status, inst_dates_3d = _decide_inst_status_and_dates(inst_df, df_top_symbols, trade_date)
    data_date_finmind = _finmind_data_date(inst_df)

    # è‹¥æ˜ç¢ºæ˜¯ã€Œä»˜è²»/æˆæ¬Š/è¢«æ“‹ã€é¡éŒ¯èª¤ï¼Œå¼·åˆ¶ UNAVAILABLE
    if inst_fetch_error and any(k in inst_fetch_error for k in ["402", "Payment Required", "403", "Unauthorized"]):
        inst_status = "UNAVAILABLE"
        inst_dates_3d = []

    # ---------- C) V15.7 Data Health Gateï¼ˆç‹€æ…‹ â†’ é™ç´šï¼‰ ----------
    # ä½ è¦å‰‡å¯«å¾—å¾ˆç¡¬ï¼šä»»ä¸€æ¢ä»¶æˆç«‹ â†’ é™ç´š
    # é€™è£¡å…ˆè½åœ°å…©å€‹ã€Œæœ€é—œéµä¸”å¯å›æº¯ã€çš„åˆ¤å®šï¼š
    # 1) inst_status != READY â†’ é™ç´šï¼ˆåŒ…å« UNAVAILABLE/PENDINGï¼‰
    # 2) data_date_finmind != trade_date â†’ é™ç´šï¼ˆå¦‚æœæœ‰ data_date_finmindï¼‰
    kill_switch = False
    v14_watch = False

    cond_inst_not_ready = (inst_status != "READY")
    cond_date_mismatch = (data_date_finmind is not None and str(data_date_finmind) != str(trade_date))

    degraded_mode = bool(cond_inst_not_ready or cond_date_mismatch or kill_switch or v14_watch)

    macro_overview = {
        # æˆäº¤é‡‘é¡ï¼šä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆï¼ˆä½ è¦æ±‚ amount_total ä½œç‚ºä¸»å€¼ï¼‰
        "amount_twse": amount_twse,
        "amount_tpex": amount_tpex,
        "amount_total": amount_total,
        "amount_sources": {
            "twse": amount_sources.get("twse"),
            "tpex": amount_sources.get("tpex"),
            "error": amount_sources.get("error"),
        },
        "avg20_amount_total_median": avg20_amount_total_median,

        # ç›¤ä¸­é‡èƒ½æ­£è¦åŒ–ï¼ˆå…©ç¨® ratio éƒ½æä¾›ï¼‰
        "progress": amount_norm.get("progress"),
        "amount_norm_cum_ratio": amount_norm.get("amount_norm_cum_ratio"),
        "amount_norm_slice_ratio": amount_norm.get("amount_norm_slice_ratio"),
        "amount_norm_label": amount_norm.get("amount_norm_label"),

        # æ³•äºº
        "inst_net": "A:0.00å„„ | B:0.00å„„",
        "trade_date": trade_date,
        "inst_status": inst_status,
        "inst_dates_3d": inst_dates_3d,
        "data_date_finmind": data_date_finmind,

        # ç³»çµ±æ——æ¨™
        "kill_switch": kill_switch,
        "v14_watch": v14_watch,
        "degraded_mode": degraded_mode,
        "data_mode": "INTRADAY" if session == SESSION_INTRADAY else "EOD",
    }

    # market_commentï¼šåªçµ¦äººé¡çœ‹ï¼ˆArbiter å¿…é ˆå¿½ç•¥ï¼‰
    macro_overview["market_comment"] = generate_market_comment_retail(macro_overview)

    # ç‚ºäº†ç›¸å®¹èˆŠå‰ç«¯ï¼šä¿ç•™ amount æ¬„ä½ï¼ˆæŒ‡å‘ amount_totalï¼‰
    macro_overview["amount"] = amount_total

    return macro_overview, inst_df


# =========================
# Streamlit App
# =========================
def app():
    st.set_page_config(page_title="Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°", layout="wide")
    st.title("Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°")

    market = st.sidebar.selectbox("Market", ["tw-share", "tw"], index=0)
    session = st.sidebar.selectbox("Session", [SESSION_INTRADAY, SESSION_EOD], index=0)

    run_btn = st.sidebar.button("Run")

    if not run_btn:
        st.info("æŒ‰å·¦å´ Run ç”¢ç”Ÿ Top æ¸…å–®èˆ‡ JSONã€‚")
        return

    # 1) Load market dataï¼ˆä½ çš„ repo å¯èƒ½æœƒæ²’æœ‰ indicesï¼Œæ‰€ä»¥é€™è£¡åªç”¨æ–¼ analyzerï¼‰
    try:
        df = _load_market_csv(market)
    except Exception as e:
        st.error(f"å¸‚å ´è³‡æ–™è®€å–å¤±æ•—ï¼š{type(e).__name__}: {str(e)}")
        st.stop()

    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

    latest_date = df["Date"].max() if "Date" in df.columns else _now_taipei()
    trade_date = _fmt_date(latest_date)

    # 2) Run analyzerï¼ˆTop æ¸…å–®ï¼‰
    df_top, err = run_analysis(df, session=session)
    if err:
        st.error(f"Analyzer error: {err}")
        st.stop()

    # 2.1) èˆªé‹ä¼°å€¼ overlay
    df_top = _apply_shipping_valuation_overrides(df_top)

    # 3) V15.7 ç‹€æ…‹åˆ¤å®šï¼ˆå¯ç›´æ¥è¦†è“‹çš„å€å¡Šï¼‰
    symbols = df_top["Symbol"].astype(str).tolist()
    macro_overview, inst_df = build_v15_7_status_block(
        session=session,
        trade_date=trade_date,
        df_top_symbols=symbols,
    )

    # 4) Merge institutional into df_topï¼ˆè‹¥ UNAVAILABLE/PENDINGï¼Œcalc_inst_3d æœƒå› PENDINGï¼‰
    df_top2 = _merge_institutional_into_df_top(df_top, inst_df, trade_date=trade_date)

    macro_data = {"overview": macro_overview, "indices": []}

    # 5) Generate JSON for Arbiter
    json_text = generate_ai_json(df_top2, market=market, session=session, macro_data=macro_data)

    # =========================
    # UI
    # =========================
    st.subheader("ä»Šæ—¥å¸‚å ´ç‹€æ…‹ï¼ˆäººé¡é–±è®€ç‰ˆï¼›Arbiter å¿…é ˆå¿½ç•¥ market_commentï¼‰")
    st.info(macro_overview.get("market_comment", ""))

    # é—œéµæ•¸æ“šé€æ˜åŒ–ï¼ˆå¯å›æº¯ï¼‰
    st.subheader("é—œéµç‹€æ…‹èˆ‡æ•¸æ“šï¼ˆå¯å›æº¯ï¼‰")
    st.write(
        {
            "trade_date": macro_overview.get("trade_date"),
            "data_mode": macro_overview.get("data_mode"),
            "amount_twse": macro_overview.get("amount_twse"),
            "amount_tpex": macro_overview.get("amount_tpex"),
            "amount_total": macro_overview.get("amount_total"),
            "avg20_amount_total_median": macro_overview.get("avg20_amount_total_median"),
            "progress": macro_overview.get("progress"),
            "amount_norm_label": macro_overview.get("amount_norm_label"),
            "amount_norm_cum_ratio": macro_overview.get("amount_norm_cum_ratio"),
            "amount_norm_slice_ratio": macro_overview.get("amount_norm_slice_ratio"),
            "inst_status": macro_overview.get("inst_status"),
            "inst_dates_3d": macro_overview.get("inst_dates_3d"),
            "data_date_finmind": macro_overview.get("data_date_finmind"),
            "degraded_mode": macro_overview.get("degraded_mode"),
            "amount_sources": macro_overview.get("amount_sources"),
        }
    )

    # èˆªé‹ä¼°å€¼å¡ï¼ˆåªé¡¯ç¤ºå‘½ä¸­è€…ï¼‰
    hit = df_top2[df_top2["Symbol"].isin(list(SHIPPING_VALUATION.keys()))].copy()
    if not hit.empty:
        st.subheader("èˆªé‹è‚¡ä¼°å€¼å¿«ç…§ï¼ˆè²¡å ±ç‹—/ç©è‚¡ç¶²ï¼›Overlayï¼‰")
        cols = ["Symbol", "Name", "Valuation_Override"]
        show = hit[cols].copy()

        def _render(v: dict) -> str:
            if not isinstance(v, dict):
                return ""
            return (
                f"OPM({v.get('opm_q_period')}): {v.get('opm_q')}% | "
                f"EPS(TTM): {v.get('eps_ttm')} | "
                f"Price({v.get('price_ref_date')}): {v.get('price_ref')} | "
                f"PEâ‰ˆ{v.get('pe_calc')} | {v.get('label')} | "
                f"ä¾†æº: {v.get('source')}"
            )

        show["ä¼°å€¼æ‘˜è¦"] = show["Valuation_Override"].apply(_render)
        st.dataframe(show[["Symbol", "Name", "ä¼°å€¼æ‘˜è¦"]], use_container_width=True)

    st.subheader("Top List")
    st.dataframe(df_top2, use_container_width=True)

    st.subheader("AI JSON (Arbiter Input)")
    st.code(json_text, language="json")

    # Save JSON
    outname = f"ai_payload_{market}_{trade_date.replace('-', '')}_{session.lower()}.json"
    outpath = DATA_DIR / outname
    outpath.write_text(json_text, encoding="utf-8")
    st.success(f"JSON å·²è¼¸å‡ºï¼š{outpath}")


if __name__ == "__main__":
    app()
