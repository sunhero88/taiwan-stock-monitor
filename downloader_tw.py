import pandas as pd
import yfinance as yf
import argparse
import requests
import os
import json
import logging
from datetime import datetime

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

CACHE_FILE = ".stock_data_cache.json"

def save_to_cache(symbol, price, volume):
    """å°‡æˆåŠŸçš„æ•¸æ“šå­˜å…¥æœ¬åœ°å¿«å–"""
    cache = {}
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r') as f:
                cache = json.load(f)
        except: pass
    
    cache[symbol] = {
        'price': price,
        'volume': volume,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    with open(CACHE_FILE, 'w') as f:
        json.dump(cache, f)

def get_from_cache(symbol):
    """å¾å¿«å–è®€å–æ•¸æ“šä¸¦çµ¦äºˆä¿å®ˆæ¬Šé‡"""
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r') as f:
            cache = json.load(f)
            if symbol in cache:
                data = cache[symbol]
                # è£œå„Ÿé‚è¼¯ï¼šæˆäº¤é‡æ‰“ 9 æŠ˜ï¼Œåƒ¹æ ¼ä¸è®Šï¼Œç¢ºä¿ç³»çµ±èƒ½è·‘ä½†ä¿æŒè­¦ç¤º
                return data['price'], data['volume'] * 0.9
    return None, None

def repair_stock_gap(symbol):
    """å‚™æ´æ–¹æ¡ˆï¼šå¤šå±¤ç´šä¿®å¾©é‚è¼¯"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    
    try:
        # å˜—è©¦ 1: yfinance å–®é»
        t = yf.Ticker(symbol)
        df = t.history(period="3d")
        if not df.empty:
            p, v = df['Close'].iloc[-1], df['Volume'].iloc[-1]
            save_to_cache(symbol, p, v)
            return p, v
        
        # å˜—è©¦ 2: Yahoo Query API
        url = f"https://query1.finance.yahoo.com/v8/finance/chart/{symbol}?interval=1d&range=1d"
        r = requests.get(url, headers=headers, timeout=10).json()
        result = r.get('chart', {}).get('result', [])
        if result:
            price = result[0]['meta']['regularMarketPrice']
            vol = result[0]['indicators']['quote'][0]['volume'][0]
            if price:
                save_to_cache(symbol, price, vol)
                return price, vol
    except Exception as e:
        logging.warning(f"âš ï¸ {symbol} ç¶²è·¯ä¿®å¾©å¤±æ•—: {e}")
    
    # å˜—è©¦ 3: æœ€å¾Œé˜²ç·š - å¿«å–è£œå„Ÿ
    p, v = get_from_cache(symbol)
    if p:
        logging.error(f"ğŸš¨ {symbol} ä½¿ç”¨å¿«å–è£œå„Ÿæ•¸æ“š (DEGRADED_MODE)")
        return p, v
        
    return None, None

def download_data(market_id):
    logging.info(f"ğŸ“¡ æ­£åœ¨ä¸‹è¼‰ {market_id} æ•¸æ“š (Predator V16.3 æ ¸å¿ƒ)...")
    tickers = ["2330.TW", "2317.TW", "2308.TW", "2454.TW", "2382.TW", "3231.TW", "2603.TW", "2609.TW"] 
    
    try:
        # åŸ·è¡Œæ‰¹æ¬¡ä¸‹è¼‰
        data = yf.download(tickers, period="1y", interval="1d", progress=False, group_by='column')
    except Exception as e:
        logging.error(f"âŒ yfinance æ‰¹æ¬¡ä¸‹è¼‰å´©æ½°: {e}")
        data = pd.DataFrame()

    df_list = []
    for symbol in tickers:
        try:
            # å–å¾—è©²è‚¡æ•¸æ“šï¼Œè‹¥ä¸å­˜åœ¨å‰‡å»ºç«‹ç©º Series
            s_close = data['Close'][symbol] if 'Close' in data and symbol in data['Close'] else pd.Series(dtype='float64')
            s_vol = data['Volume'][symbol] if 'Volume' in data and symbol in data['Volume'] else pd.Series(dtype='float64')
            
            # åµæ¸¬ç¼ºå¤± (ç©ºæ•¸æ“šæˆ–æœ€å¾Œä¸€ç­†æ˜¯ NaN)
            if s_close.empty or pd.isna(s_close.iloc[-1]):
                logging.warning(f"âš ï¸ {symbol} æ•¸æ“šç¼ºå¤±ï¼Œå•Ÿå‹•è£œå„Ÿé‚è¼¯...")
                p, v = repair_stock_gap(symbol)
                
                if p is not None:
                    # å¦‚æœ yf ä¸‹è¼‰åŸæœ¬æ˜¯ç©ºçš„ï¼Œå»ºç«‹ä¸€å€‹åŸºç¤ Index
                    if s_close.empty:
                        idx = pd.to_datetime([datetime.now().date()])
                        s_close = pd.Series([p], index=idx)
                        s_vol = pd.Series([v], index=idx)
                    else:
                        # ä¿®æ­£æœ€å¾Œä¸€ç­†æ•¸æ“š
                        s_close.iloc[-1] = p
                        s_vol.iloc[-1] = v
                    save_to_cache(symbol, p, v)

            if not s_close.empty:
                temp_df = pd.DataFrame({
                    'Date': s_close.index,
                    'Symbol': symbol,
                    'Close': s_close.values,
                    'Volume': s_vol.values
                })
                df_list.append(temp_df)
                
        except Exception as e:
            logging.error(f"âŒ {symbol} è™•ç†å¤±æ•—: {e}")

    if df_list:
        final_df = pd.concat(df_list).dropna(subset=['Close'])
        output_file = f"data_{market_id}.csv"
        final_df.to_csv(output_file, index=False)
        logging.info(f"âœ… æ•¸æ“šæ›´æ–°å®Œæˆ: {output_file}")
    else:
        logging.critical("âŒ åš´é‡éŒ¯èª¤ï¼šå®Œå…¨ç„¡æ³•å–å¾—ä»»ä½•æ•¸æ“šï¼")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--market', default='tw-share')
    args = parser.parse_args()
    download_data(args.market)
