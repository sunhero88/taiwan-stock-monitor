import pandas as pd
import yfinance as yf
import argparse
import requests
import os
import json
import logging
from datetime import datetime

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

CACHE_FILE = ".stock_data_cache.json"

def get_tpex_amount_official():
    """å°ˆé–€ä¿®å¾©ä¸Šæ«ƒæˆäº¤é‡æŠ“å–å¤±æ•—çš„å•é¡Œ (ç ´è§£ REDIRECT_ERRORS)"""
    today = datetime.now()
    # æ«ƒè²·ä¸­å¿ƒä½¿ç”¨æ°‘åœ‹å¹´æ ¼å¼: 115/02/06
    roc_date = f"{today.year - 1911}/{today.strftime('%m/%d')}"
    url = "https://www.tpex.org.tw/web/stock/aftertrading/daily_trading_info/st43_result.php"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Referer': 'https://www.tpex.org.tw/zh-tw/mainboard/trading/info/stock-pricing.html'
    }
    params = {'l': 'zh-tw', 'd': roc_date, 'se': 'EW'}

    try:
        r = requests.get(url, params=params, headers=headers, timeout=10, allow_redirects=False)
        if r.status_code == 200:
            data = r.json()
            amount = int(data.get('tse_amount', 0))
            if amount > 0:
                logging.info(f"âœ… æˆåŠŸé€éå®˜æ–¹ API å–å¾—ä¸Šæ«ƒæˆäº¤é‡: {amount}")
                return amount, "TPEX_OFFICIAL_OK"
    except Exception as e:
        logging.warning(f"âš ï¸ TPEX å®˜æ–¹ API æŠ“å–å¤±æ•—: {e}")

    # å‚™æ´ 1: yfinance æ«ƒè²·æŒ‡æ•¸
    try:
        tpex_idx = yf.Ticker("^TWOII")
        hist = tpex_idx.history(period="1d")
        if not hist.empty:
            est_amount = int(hist['Volume'].iloc[-1] * 0.8) # ç°¡æ˜“æ›ç®—æ¯”ä¾‹
            logging.info(f"ğŸ’¡ ä½¿ç”¨ yfinance å‚™æ´ä¼°ç®—ä¸Šæ«ƒæˆäº¤é‡: {est_amount}")
            return est_amount, "TPEX_YFINANCE_ESTIMATE"
    except: pass

    logging.error("ğŸš¨ TPEX æ‰€æœ‰ä¾†æºå‡å¤±æ•—ï¼Œä½¿ç”¨ä¿å®ˆæ­·å²å€¼")
    return 80000000000, "TPEX_FALLBACK_DEGRADED"

def save_to_cache(symbol, price, volume):
    """å°‡æˆåŠŸçš„æ•¸æ“šå­˜å…¥æœ¬åœ°å¿«å–"""
    cache = {}
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r') as f:
                cache = json.load(f)
        except: pass
    
    cache[symbol] = {
        'price': price,
        'volume': volume,
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    with open(CACHE_FILE, 'w') as f:
        json.dump(cache, f)

def get_from_cache(symbol):
    """å¾å¿«å–è®€å–æ•¸æ“šä¸¦çµ¦äºˆä¿å®ˆæ¬Šé‡"""
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r') as f:
            cache = json.load(f)
            if symbol in cache:
                data = cache[symbol]
                return data['price'], data['volume'] * 0.9
    return None, None

def repair_stock_gap(symbol):
    """å‚™æ´æ–¹æ¡ˆï¼šå¤šå±¤ç´šä¿®å¾©é‚è¼¯"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
    try:
        t = yf.Ticker(symbol)
        df = t.history(period="3d")
        if not df.empty:
            p, v = df['Close'].iloc[-1], df['Volume'].iloc[-1]
            return p, v
    except Exception as e:
        logging.warning(f"âš ï¸ {symbol} ç¶²è·¯ä¿®å¾©å¤±æ•—: {e}")
    
    p, v = get_from_cache(symbol)
    if p: return p, v
    return None, None

def download_data(market_id):
    logging.info(f"ğŸ“¡ æ­£åœ¨ä¸‹è¼‰ {market_id} æ•¸æ“š (Predator V16.3 æ ¸å¿ƒ)...")
    tickers = ["2330.TW", "2317.TW", "2308.TW", "2454.TW", "2382.TW", "3231.TW", "2603.TW", "2609.TW"] 
    
    # åŸ·è¡Œå€‹è‚¡æ‰¹æ¬¡ä¸‹è¼‰
    try:
        data = yf.download(tickers, period="1y", interval="1d", progress=False, group_by='column')
    except Exception as e:
        logging.error(f"âŒ yfinance æ‰¹æ¬¡ä¸‹è¼‰å´©æ½°: {e}")
        data = pd.DataFrame()

    df_list = []
    for symbol in tickers:
        try:
            s_close = data['Close'][symbol] if 'Close' in data and symbol in data['Close'] else pd.Series(dtype='float64')
            s_vol = data['Volume'][symbol] if 'Volume' in data and symbol in data['Volume'] else pd.Series(dtype='float64')
            
            if s_close.empty or pd.isna(s_close.iloc[-1]):
                p, v = repair_stock_gap(symbol)
                if p is not None:
                    if s_close.empty:
                        idx = pd.to_datetime([datetime.now().date()])
                        s_close = pd.Series([p], index=idx)
                        s_vol = pd.Series([v], index=idx)
                    else:
                        s_close.iloc[-1] = p
                        s_vol.iloc[-1] = v
                    save_to_cache(symbol, p, v)

            if not s_close.empty:
                temp_df = pd.DataFrame({
                    'Date': s_close.index,
                    'Symbol': symbol,
                    'Close': s_close.values,
                    'Volume': s_vol.values
                })
                df_list.append(temp_df)
        except Exception as e:
            logging.error(f"âŒ {symbol} è™•ç†å¤±æ•—: {e}")

    # --- é—œéµæ•´åˆï¼šè¨ˆç®—å…¨å¸‚å ´ç¸½é‡ä¸¦å„²å­˜ JSON ---
    tpex_amount, tpex_src = get_tpex_amount_official()
    # å‡è¨­ä¸Šå¸‚æˆäº¤é‡å¤§ç´„ç‚ºé€™å¹¾æª”æ¬Šå€¼è‚¡æˆäº¤é¡ç¸½å’Œçš„ 2.5 å€ (æ­¤è™•åƒ…ç‚ºé‚è¼¯ç¤ºæ„ï¼Œå¯ä¾éœ€æ±‚ç²¾ç¢ºæŠ“å–)
    # å»ºè­°ï¼šPredator é‚„æ˜¯è¦è®€å–é€™å€‹ç”¢å‡ºçš„ market_amount.json
    market_status = {
        "date": datetime.now().strftime("%Y-%m-%d"),
        "tpex_amount": tpex_amount,
        "tpex_source": tpex_src,
        "status": "OK" if "OFFICIAL" in tpex_src else "DEGRADED"
    }
    with open("market_amount.json", "w") as f:
        json.dump(market_status, f, indent=4)

    if df_list:
        final_df = pd.concat(df_list).dropna(subset=['Close'])
        output_file = f"data_{market_id}.csv"
        final_df.to_csv(output_file, index=False)
        logging.info(f"âœ… æ•¸æ“šèˆ‡å¸‚å ´ç¸½é‡æ›´æ–°å®Œæˆ: {output_file}")
    else:
        logging.critical("âŒ åš´é‡éŒ¯èª¤ï¼šå®Œå…¨ç„¡æ³•å–å¾—ä»»ä½•æ•¸æ“šï¼")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--market', default='tw-share')
    args = parser.parse_args()
    download_data(args.market)
