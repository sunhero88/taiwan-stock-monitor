import pandas as pd
import yfinance as yf
import requests
import os
import json
import logging
from datetime import datetime
from bs4 import BeautifulSoup
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# é…ç½®
logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)
MARKET_JSON = os.path.join(DATA_DIR, "market_amount.json")

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Referer': 'https://www.tpex.org.tw/'
}

session = requests.Session()
retry = Retry(total=3, backoff_factor=1, status_forcelist=[429, 500, 502, 503, 504])
adapter = HTTPAdapter(max_retries=retry)
session.mount('http://', adapter)
session.mount('https://', adapter)

def roc_date(dt):
    """è½‰ ROC å¹´/æœˆ/æ—¥ æ ¼å¼ï¼Œå¦‚ 115/02/06"""
    roc_year = dt.year - 1911
    return f"{roc_year:03d}/{dt.strftime('%m/%d')}"

# ç¬¬ä¸€é‡ï¼šTWSE æ—¥ç¸½æˆäº¤é‡‘é¡ (MI_INDEX æˆ– STOCK_DAY_ALL)
def get_twse_daily_amount():
    dt_str = datetime.now().strftime("%Y%m%d")
    url = f"https://www.twse.com.tw/exchangeReport/MI_INDEX?response=json&date={dt_str}&type=ALLBUT0999"
    try:
        r = session.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            data = r.json()
            if 'data9' in data:  # MI_INDEX æœ‰æ™‚ç”¨ data9 ç‚ºç¸½è¦½
                total_amt_str = data['data9'][0][2]  # èª¿æ•´ç´¢å¼•ï¼Œè¦–å¯¦éš›ç‚ºç¸½æˆäº¤é‡‘é¡
                return int(float(total_amt_str.replace(',', ''))), "TWSE_MI_INDEX"
    except Exception as e:
        logging.warning(f"TWSE MI_INDEX å¤±æ•—: {e}")
    
    # å‚™æ´ STOCK_DAY_ALL
    url_all = f"https://www.twse.com.tw/exchangeReport/STOCK_DAY_ALL?response=json&date={dt_str}"
    try:
        r = session.get(url_all, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            items = r.json()
            total = sum(int(float(item.get('æˆäº¤é‡‘é¡', 0))) for item in items if item.get('æˆäº¤é‡‘é¡'))
            return total, "TWSE_STOCK_DAY_ALL"
    except:
        pass
    return 0, "TWSE_FAILED"

# ç¬¬äºŒé‡ï¼šTPEX - å˜—è©¦ st43_result.php æ­£ç¢ºåƒæ•¸ + fallback HTML
def get_tpex_st43():
    roc_d = roc_date(datetime.now())
    url = f"https://www.tpex.org.tw/web/stock/aftertrading/daily_trading_info/st43_result.php?l=zh-tw&d={roc_d}&se=EW"
    try:
        r = session.get(url, headers=HEADERS, timeout=15)
        if r.status_code == 200 and 'errors' not in r.url:
            data = r.json()
            if 'reportData' in data and data['reportData']:
                # æœ€å¾Œä¸€åˆ—åˆè¨ˆï¼Œç¬¬3æ¬„ (ç´¢å¼•2) é€šå¸¸ç‚ºæˆäº¤é‡‘é¡
                total_str = data['reportData'][-1][2]
                amount = int(float(total_str.replace(',', '')) * 100000000)  # è‹¥å–®ä½å„„å…ƒï¼Œè½‰å…ƒ
                logging.info(f"âœ… TPEX st43 æˆåŠŸ: {amount:,}")
                return amount, "TPEX_ST43"
    except Exception as e:
        logging.warning(f"TPEX st43 å¤±æ•—: {e} (å¯èƒ½ redirect)")
    return None, None

# ç¬¬ä¸‰é‡ï¼šTPEX HTML parse (daily statistics page)
def get_tpex_html_parse():
    url = "https://www.tpex.org.tw/zh-tw/mainboard/trading/statistics/daily.html"
    try:
        r = session.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        # æ‰¾ç¸½æˆäº¤é‡‘é¡æ–‡å­— (èª¿æ•´ selector ä¾å¯¦éš› HTML)
        total_elem = soup.find(string=lambda t: "ç¸½æˆäº¤é‡‘é¡" in str(t) if t else False)
        if total_elem:
            amt_text = total_elem.find_next('td').text.strip() if total_elem.find_next('td') else ""
            amt_text = amt_text.replace(',', '').replace('å„„å…ƒ', '')
            amount = int(float(amt_text)) * 100000000  # å„„å…ƒè½‰å…ƒ
            return amount, "TPEX_HTML_PARSE"
        # è‹¥ç„¡ï¼Œè©¦æ‰¾è¡¨æ ¼æœ€å¾Œåˆè¨ˆ
        table = soup.find('table', {'class': 'table'})  # èª¿æ•´ class
        if table:
            rows = table.find_all('tr')
            if rows:
                last_row = rows[-1].find_all('td')
                if len(last_row) > 2:
                    amt_str = last_row[2].text.strip().replace(',', '')
                    amount = int(float(amt_str)) * 100000000
                    return amount, "TPEX_TABLE_PARSE"
    except Exception as e:
        logging.warning(f"TPEX HTML parse å¤±æ•—: {e}")
    return None, None

# ç¬¬å››é‡ï¼šYahoo ä¼°ç®— (^TWO)
def get_yahoo_estimate():
    try:
        otc = yf.Ticker("^TWO").history(period="2d", prepost=False)
        if not otc.empty:
            vol = otc['Volume'].iloc[-1]
            close = otc['Close'].iloc[-1]
            est = int(vol * close * 0.58)  # èª¿åˆ° 0.58 æ›´æº– (æ­·å²æ¯”å°)
            logging.info(f"âš ï¸ Yahoo ä¼°ç®—ä¸Šæ«ƒ: {est:,}")
            return est, "YAHOO_ESTIMATE"
    except Exception as e:
        logging.error(f"Yahoo ä¼°ç®—å¤±æ•—: {e}")
    return 0, "FAILED"

# ä¸»ç¨‹åº
def main():
    logging.info("ğŸš€ Predator V16.3.9+ TPEX ä¿®è£œç‰ˆ åŸ·è¡Œä¸­...")

    # TWSE
    tse_amount, tse_src = get_twse_daily_amount()

    # TPEX å¤šå±¤
    otc_amount, otc_src = get_tpex_st43()
    if otc_amount is None:
        otc_amount, otc_src = get_tpex_html_parse()
    if otc_amount is None or otc_amount == 0:
        otc_amount, otc_src = get_yahoo_estimate()

    # å€‹è‚¡ + é›™é´»æ•‘æ´
    tickers = ["2330.TW", "2317.TW", "2454.TW", "3324.TW", "2308.TW", "2382.TW", "3231.TW", "3017.TW", "2603.TW"]
    data = yf.download(tickers, period="5d", group_by='ticker', threads=False, prepost=False)

    stock_list = []
    for s in tickers:
        try:
            df = data[s] if s in data else pd.DataFrame()
            if not df.empty:
                p = df['Close'].dropna().iloc[-1]
                v = df['Volume'].dropna().iloc[-1]
                stock_list.append({"Symbol": s, "Price": float(p), "Volume": int(v)})
                continue
        except:
            pass
        # å–®æª”æ•‘æ´
        logging.info(f"ğŸ”§ æ•‘æ´ {s}")
        fix = yf.Ticker(s).history(period="3d", prepost=False)
        if not fix.empty:
            stock_list.append({"Symbol": s, "Price": float(fix['Close'].iloc[-1]), "Volume": int(fix['Volume'].iloc[-1])})

    # è¼¸å‡º
    market_output = {
        "trade_date": datetime.now().strftime("%Y-%m-%d"),
        "amount_twse": tse_amount,
        "amount_tpex": otc_amount,
        "amount_total": tse_amount + otc_amount,
        "source_twse": tse_src,
        "source_tpex": otc_src,
        "status": "OK" if otc_amount > 0 else "DEGRADED",
        "integrity": {
            "tickers_count": len(stock_list),
            "amount_partial": otc_amount == 0
        }
    }

    with open(MARKET_JSON, 'w', encoding='utf-8') as f:
        json.dump(market_output, f, indent=4, ensure_ascii=False)
    
    pd.DataFrame(stock_list).to_csv(os.path.join(DATA_DIR, "data_tw-share.csv"), index=False)
    logging.info(f"å®Œæˆã€‚ä¸Šæ«ƒæº: {otc_src} | ç¸½é¡: {market_output['amount_total']:,}")

if __name__ == "__main__":
    main()
