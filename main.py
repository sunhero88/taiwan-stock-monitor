# main.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
from datetime import datetime, time, timedelta, timezone

import pandas as pd
import streamlit as st

from analyzer import run_analysis, generate_ai_json, SESSION_INTRADAY, SESSION_EOD

# ä½ çš„ç›¤ä¸­æˆäº¤é‡‘é¡æ¨¡çµ„ï¼ˆå¯ç”¨å°±ç”¨ï¼›ä¸å¯ç”¨å°±é™ç´šä½†ä¸å½±éŸ¿ã€Œæœªé–‹ç›¤é¡¯ç¤ºæ˜¨æ—¥ã€ï¼‰
from market_amount import fetch_amount_total, intraday_norm, _now_taipei, TRADING_START

TZ_TAIPEI = timezone(timedelta(hours=8))


# =========================
# 0) èˆªé‹è‚¡ä¼°å€¼ï¼ˆæ‰‹å‹•è¦†è“‹å±¤ï¼‰
# =========================
SHIPPING_VALUATION = {
    "2603.TW": {
        "name_zh": "é•·æ¦®",
        "sector": "èˆªé‹",
        "opm_q": 22.73,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 41.92,
        "price_ref": 192.54,
        "price_ref_date": "2026-01-22",
        "pe_calc": 4.59,
        "label": "ğŸŸ¢ æ¥µåº¦ä½ä¼° (Deep Value)",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
    "2609.TW": {
        "name_zh": "é™½æ˜",
        "sector": "èˆªé‹",
        "opm_q": 10.49,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 7.83,
        "price_ref": 55.57,
        "price_ref_date": "2026-01-22",
        "pe_calc": 7.09,
        "label": "ğŸŸ¡",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
}


def _fmt_date(dt) -> str:
    try:
        return pd.to_datetime(dt).strftime("%Y-%m-%d")
    except Exception:
        return datetime.now().strftime("%Y-%m-%d")


def _load_market_csv(market: str) -> pd.DataFrame:
    # ä½  repo ç›®å‰ç”¨ yfinance ç”Ÿæˆï¼šdata_{market}.csv
    # æ³¨æ„ï¼šä½ å¾Œä¾†å·²æŠŠè³‡æ–™æ”¾é€² data/ è³‡æ–™å¤¾ï¼Œé€™è£¡åŒæ™‚æ”¯æ´æ ¹ç›®éŒ„èˆ‡ data/ã€‚
    candidates = [
        f"data/data_{market}.csv",
        f"data_{market}.csv",
        "data/data_tw-share.csv",
        "data_tw-share.csv",
        "data/data_tw.csv",
        "data_tw.csv",
    ]
    fname = None
    for p in candidates:
        if os.path.exists(p):
            fname = p
            break
    if not fname:
        raise FileNotFoundError("æ‰¾ä¸åˆ°å¸‚å ´è³‡æ–™æª”ï¼šè«‹ç¢ºèª data/data_tw-share.csv æˆ– data_tw-share.csv å­˜åœ¨")

    df = pd.read_csv(fname)
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    return df


def _pick_trade_date_for_session(df: pd.DataFrame, session: str) -> tuple[pd.Timestamp, str]:
    """
    - EODï¼šå–è³‡æ–™ä¸­æœ€å¾Œä¸€å€‹æ—¥æœŸï¼ˆè¦–ç‚ºã€Œæ˜¨æ—¥æ”¶ç›¤ã€ï¼‰
    - INTRADAYï¼šå–æœ€å¾Œä¸€å€‹æ—¥æœŸï¼ˆä½ çš„è³‡æ–™æ˜¯æ—¥Kï¼Œæ‰€ä»¥ä»ç„¶ç”¨æœ€å¾Œä¸€æ—¥åšåŸºæº–ï¼‰
    """
    latest = df["Date"].max()
    return latest, _fmt_date(latest)


def _apply_shipping_valuation_overrides(df_top: pd.DataFrame) -> pd.DataFrame:
    out = df_top.copy()

    def _inject(row: pd.Series) -> pd.Series:
        sym = str(row.get("Symbol", "")).strip()
        info = SHIPPING_VALUATION.get(sym)
        if not info:
            return row

        if not row.get("Name"):
            row["Name"] = info.get("name_zh", sym)

        row["Valuation_Override"] = {
            "sector": info.get("sector"),
            "opm_q": float(info.get("opm_q", 0.0)),
            "opm_q_period": info.get("opm_q_period"),
            "eps_ttm": float(info.get("eps_ttm", 0.0)),
            "price_ref": float(info.get("price_ref", 0.0)),
            "price_ref_date": info.get("price_ref_date"),
            "pe_calc": float(info.get("pe_calc", 0.0)),
            "label": info.get("label"),
            "source": info.get("source"),
        }
        return row

    return out.apply(_inject, axis=1)


def _load_global_summary() -> pd.DataFrame:
    """
    è®€å–ä½  repo çš„å…¨çƒæ‘˜è¦ï¼šdata/global_market_summary.csv
    æ¬„ä½ï¼šMarket, Symbol, Change, Value
    """
    candidates = [
        "data/global_market_summary.csv",
        "global_market_summary.csv",
    ]
    for p in candidates:
        if os.path.exists(p):
            df = pd.read_csv(p)
            return df
    return pd.DataFrame(columns=["Market", "Symbol", "Change", "Value"])


def _is_premarket(now: datetime) -> bool:
    start_dt = now.replace(hour=TRADING_START.hour, minute=TRADING_START.minute, second=0, microsecond=0)
    return now < start_dt


def _market_comment_v15_7(overview: dict) -> str:
    """
    V15.7 å£èªåŒ–è£æ±ºè¨Šæ¯ï¼ˆå¯å›æº¯æ¬„ä½ï¼‰
    """
    session = overview.get("data_mode")
    degraded = bool(overview.get("degraded_mode", False))
    inst_status = overview.get("inst_status", "UNAVAILABLE")

    if session == "EOD":
        # æœªé–‹ç›¤ï¼šé¡¯ç¤ºæ˜¨æ—¥ç‹€æ…‹ï¼Œä¸åšç›¤ä¸­æˆäº¤é‡‘é¡è£æ±º
        return "ç›®å‰å°šæœªé–‹ç›¤ï¼šç•«é¢é¡¯ç¤ºã€æ˜¨æ—¥æ”¶ç›¤ï¼ˆEODï¼‰ã€å¸‚å ´ç‹€æ…‹èˆ‡ Top Listã€‚"

    # INTRADAYï¼šæ‰éœ€è¦ç›¤ä¸­æˆäº¤é‡‘é¡é©—è­‰
    label = overview.get("amount_norm_label", "UNKNOWN")
    if degraded:
        return f"ç›¤ä¸­è³‡æ–™é™ç´šæˆç«‹ï¼ˆé‡èƒ½æ¨™ç±¤={label} / æ³•äººç‹€æ…‹={inst_status}ï¼‰ï¼šç¦æ­¢ BUY/TRIALã€‚"

    return f"ç›¤ä¸­è³‡æ–™å¯ç”¨ï¼ˆé‡èƒ½æ¨™ç±¤={label} / æ³•äººç‹€æ…‹={inst_status}ï¼‰ï¼šå¯ä¾æ¨¡å¼è¦å‰‡åŸ·è¡Œã€‚"


def app():
    st.set_page_config(page_title="Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°", layout="wide")
    st.title("Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°")

    now = datetime.now(tz=TZ_TAIPEI)
    premarket = _is_premarket(now)

    market = st.sidebar.selectbox("Market", ["tw-share", "tw"], index=0)

    # âœ… é—œéµï¼šæœªé–‹ç›¤è‡ªå‹•é–å®š EODï¼ˆæ˜¨æ—¥ï¼‰
    default_session = SESSION_EOD if premarket else SESSION_INTRADAY
    session = st.sidebar.selectbox("Session", [SESSION_INTRADAY, SESSION_EOD], index=0 if default_session == SESSION_INTRADAY else 1)

    run_btn = st.sidebar.button("Run")
    if not run_btn:
        st.info("æŒ‰å·¦å´ Run ç”¢ç”Ÿæ˜¨æ—¥ï¼ˆEODï¼‰/ç›¤ä¸­ï¼ˆINTRADAYï¼‰å¸‚å ´æ‘˜è¦ã€å…¨çƒæ‘˜è¦èˆ‡ Top æ¸…å–®ã€‚")
        return

    df = _load_market_csv(market)
    latest_date, trade_date = _pick_trade_date_for_session(df, session=session)

    # 1) Analyzerï¼ˆç”¨ä½ ç¾æœ‰é‚è¼¯ç”¢å‡º Top Listï¼‰
    df_top, err = run_analysis(df, session=session)
    if err:
        st.error(f"Analyzer error: {err}")
        return

    df_top = _apply_shipping_valuation_overrides(df_top)

    # 2) å…¨çƒæ‘˜è¦ï¼ˆç¾è‚¡/æ—¥ç¶“/åŒ¯ç‡ç­‰ï¼‰â€”â€”å…è²»ä¾†æº
    global_df = _load_global_summary()

    # 3) æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆ amount_totalï¼‰
    #    âœ… æ³¨æ„ï¼šåªæœ‰ INTRADAY æ‰éœ€è¦åšã€Œç›¤ä¸­é‡èƒ½æ­£è¦åŒ–ã€èˆ‡è£æ±º
    amount_twse = None
    amount_tpex = None
    amount_total = None
    amount_sources = {"twse": None, "tpex": None, "error": None}
    norm = {"progress": None, "amount_norm_cum_ratio": None, "amount_norm_slice_ratio": None, "amount_norm_label": "UNKNOWN"}

    if session == SESSION_INTRADAY:
        try:
            ma = fetch_amount_total()
            amount_twse = ma.amount_twse
            amount_tpex = ma.amount_tpex
            amount_total = ma.amount_total
            amount_sources["twse"] = ma.source_twse
            amount_sources["tpex"] = ma.source_tpex

            # 20D medianï¼ˆç”¨ä½ æœ¬åœ° yfinance æ—¥Kç¸½é¡æ›¿ä»£ï¼šå…è²»ã€å¯é‡ç¾ï¼‰
            # é€™è£¡ç”¨ã€Œä½ çš„æˆåˆ†è‚¡æˆäº¤é¡ç¸½å’Œã€ç•¶ä½œ proxy baselineï¼ˆä¸æ˜¯å…¨å¸‚å ´ï¼Œä½†å¯è®“ç›¤ä¸­ä¸è¦å‹•ä¸å‹• LOWï¼‰
            # ä½ è‹¥ä¹‹å¾Œé¡˜æ„å†åšã€Œå…¨å¸‚å ´ amount_total_history.csvã€å¯æ›¿æ›
            d = df.copy()
            d = d.dropna(subset=["Date"])
            d = d.sort_values("Date")
            d["Close"] = pd.to_numeric(d["Close"], errors="coerce").fillna(0)
            d["Volume"] = pd.to_numeric(d["Volume"], errors="coerce").fillna(0)
            daily_amt = d.groupby("Date").apply(lambda x: float((x["Close"] * x["Volume"]).sum()))
            avg20_median = float(daily_amt.tail(20).median()) if len(daily_amt) >= 5 else None

            norm = intraday_norm(
                amount_total_now=int(amount_total),
                amount_total_prev=None,  # ä½ è‹¥ä¹‹å¾Œå­˜ 5 åˆ†é˜å‰å€¼å¯è£œ
                avg20_amount_total=avg20_median,
                now=_now_taipei(),
                alpha=0.65,
            )
            norm["avg20_amount_total_median"] = avg20_median

        except Exception as e:
            amount_sources["error"] = f"{type(e).__name__}: {str(e)}"

    # 4) æ³•äººç‹€æ…‹ï¼ˆFinMind å…è²»è¢« 402 æ“‹ä½ â†’ ç›´æ¥æ¨™ UNAVAILABLEï¼‰
    inst_status = "UNAVAILABLE"
    inst_dates_3d = []
    data_date_finmind = None

    # 5) V15.7 è£æ±ºï¼šdegraded_mode
    #    âœ… åŸå‰‡ï¼šEODï¼ˆæœªé–‹ç›¤ï¼‰ä¸å› ç‚ºç›¤ä¸­æˆäº¤é‡‘é¡æŠ“ä¸åˆ°è€Œ degraded
    if session == SESSION_EOD:
        degraded_mode = False
    else:
        # INTRADAYï¼šè‹¥æˆäº¤é‡‘é¡æŠ“ä¸åˆ°ï¼Œæˆ– label UNKNOWN â†’ degraded
        label = norm.get("amount_norm_label", "UNKNOWN")
        degraded_mode = (amount_total is None) or (label == "UNKNOWN")

    macro_overview = {
        "amount_twse": f"{amount_twse:,}" if isinstance(amount_twse, int) else "å¾…æ›´æ–°",
        "amount_tpex": f"{amount_tpex:,}" if isinstance(amount_tpex, int) else "å¾…æ›´æ–°",
        "amount_total": f"{amount_total:,}" if isinstance(amount_total, int) else "å¾…æ›´æ–°",
        "amount_sources": amount_sources,
        "avg20_amount_total_median": norm.get("avg20_amount_total_median"),
        "progress": norm.get("progress"),
        "amount_norm_cum_ratio": norm.get("amount_norm_cum_ratio"),
        "amount_norm_slice_ratio": norm.get("amount_norm_slice_ratio"),
        "amount_norm_label": norm.get("amount_norm_label", "UNKNOWN"),
        "inst_net": "A:0.00å„„ | B:0.00å„„",
        "trade_date": trade_date,
        "inst_status": inst_status,
        "inst_dates_3d": inst_dates_3d,
        "data_date_finmind": data_date_finmind,
        "kill_switch": False,
        "v14_watch": False,
        "degraded_mode": degraded_mode,
        "data_mode": "INTRADAY" if session == SESSION_INTRADAY else "EOD",
    }
    macro_overview["market_comment"] = _market_comment_v15_7(macro_overview)

    macro_data = {"overview": macro_overview, "indices": []}

    json_text = generate_ai_json(df_top, market=market, session=session, macro_data=macro_data)

    # =========================
    # UI
    # =========================
    st.subheader("ä»Šæ—¥å¸‚å ´ç‹€æ…‹åˆ¤æ–·ï¼ˆV15.7 è£æ±ºï¼‰")
    st.info(macro_overview["market_comment"])

    st.subheader("å…¨çƒå¸‚å ´æ‘˜è¦ï¼ˆç¾è‚¡/æ—¥ç¶“/åŒ¯ç‡ï¼‰")
    if global_df.empty:
        st.warning("æ‰¾ä¸åˆ° data/global_market_summary.csvï¼Œè«‹ç¢ºèª GitHub Actions æœ‰ç”¢å‡ºä¸¦ commit åˆ° repoã€‚")
    else:
        # è®“äººé¡çœ‹å¾—æ‡‚ï¼šåªä¿ç•™é—œéµæ¬„ä½
        view = global_df.copy()
        # Change å¯èƒ½æ˜¯å°æ•¸ï¼ˆä¾‹å¦‚ 0.47 è¡¨ç¤º +0.47%ï¼‰ï¼Œä½ å¯ä»¥ä¾ä½ çš„ç”¢è£½è¦æ ¼èª¿æ•´
        st.dataframe(view, use_container_width=True)

    st.subheader("å¸‚å ´æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚ + ä¸Šæ«ƒ = amount_totalï¼‰")
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("TWSE ä¸Šå¸‚", macro_overview["amount_twse"])
    c2.metric("TPEx ä¸Šæ«ƒ", macro_overview["amount_tpex"])
    c3.metric("Total åˆè¨ˆ", macro_overview["amount_total"])
    c4.metric("20D Median(ä»£ç†)", str(macro_overview["avg20_amount_total_median"]))

    st.caption(f"ä¾†æº/éŒ¯èª¤ï¼š{macro_overview['amount_sources']}")

    st.subheader("INTRADAY é‡èƒ½æ­£è¦åŒ–ï¼ˆé¿å…æ—©ç›¤èª¤åˆ¤ LOWï¼‰")
    st.json(
        {
            "progress": macro_overview["progress"],
            "cum_ratio(ç©©å¥å‹ç”¨)": macro_overview["amount_norm_cum_ratio"],
            "slice_ratio(ä¿å®ˆå‹ç”¨)": macro_overview["amount_norm_slice_ratio"],
            "label": macro_overview["amount_norm_label"],
        }
    )

    st.subheader("Top List")
    st.dataframe(df_top, use_container_width=True)

    st.subheader("AI JSON (Arbiter Input)")
    st.code(json_text, language="json")

    outname = f"ai_payload_{market}_{trade_date.replace('-', '')}_{'intraday' if session==SESSION_INTRADAY else 'eod'}.json"
    with open(outname, "w", encoding="utf-8") as f:
        f.write(json_text)
    st.success(f"JSON å·²è¼¸å‡ºï¼š{outname}")


if __name__ == "__main__":
    app()
