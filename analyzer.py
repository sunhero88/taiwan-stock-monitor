# analyzer.py
# -*- coding: utf-8 -*-
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

SESSION_PREOPEN = "PREOPEN"   # ç›¤å‰ï¼ˆè¼¸å…¥æ˜¨æ—¥/æœ€å¾Œæ”¶ç›¤æ—¥çš„å¤§ç›¤ï¼‰
SESSION_INTRADAY = "INTRADAY" # ç›¤ä¸­ï¼ˆè¼¸å…¥ç•¶ä¸‹å¤§ç›¤ï¼‰
SESSION_EOD = "EOD"           # ç›¤å¾Œï¼ˆè¼¸å…¥ç•¶æ—¥æ”¶ç›¤å¤§ç›¤ï¼‰


@dataclass
class AnalyzerConfig:
    topn: int = 20
    min_history_days: int = 60
    vol_lookback: int = 20
    ma_fast: int = 20
    ma_slow: int = 60
    mom_5d: int = 5
    mom_20d: int = 20


def _ensure_columns(df: pd.DataFrame) -> pd.DataFrame:
    required = {"Date", "Symbol", "Close", "Volume"}
    missing = required - set(df.columns)
    if missing:
        raise ValueError(f"Market CSV ç¼ºæ¬„ä½ï¼š{sorted(list(missing))}ï¼›éœ€è¦ Date, Symbol, Close, Volume")
    out = df.copy()
    out["Date"] = pd.to_datetime(out["Date"], errors="coerce")
    out["Symbol"] = out["Symbol"].astype(str)
    out["Close"] = pd.to_numeric(out["Close"], errors="coerce")
    out["Volume"] = pd.to_numeric(out["Volume"], errors="coerce")
    out = out.dropna(subset=["Date", "Symbol", "Close"]).copy()
    out["Volume"] = out["Volume"].fillna(0)
    return out


def _calc_features(df: pd.DataFrame, cfg: AnalyzerConfig) -> pd.DataFrame:
    """
    ä»¥ã€Œæ¯æª”è‚¡ç¥¨ã€åš rolling æŒ‡æ¨™ï¼Œå†å–æœ€å¾Œä¸€ç­†ä½œç‚ºç•¶æ—¥(æˆ–ç›¤ä¸­æœ€æ–°)å¿«ç…§ã€‚
    """
    d = df.sort_values(["Symbol", "Date"]).copy()

    g = d.groupby("Symbol", group_keys=False)
    d["ma20"] = g["Close"].transform(lambda s: s.rolling(cfg.ma_fast, min_periods=cfg.ma_fast).mean())
    d["ma60"] = g["Close"].transform(lambda s: s.rolling(cfg.ma_slow, min_periods=cfg.ma_slow).mean())
    d["vol20"] = g["Volume"].transform(lambda s: s.rolling(cfg.vol_lookback, min_periods=cfg.vol_lookback).mean())

    # å ±é…¬/å‹•èƒ½
    d["ret_5d"] = g["Close"].transform(lambda s: s.pct_change(cfg.mom_5d))
    d["ret_20d"] = g["Close"].transform(lambda s: s.pct_change(cfg.mom_20d))

    # MA_Biasï¼šç”¨ MA20
    d["ma_bias_pct"] = (d["Close"] / d["ma20"] - 1.0) * 100.0

    # é‡èƒ½æ¯”
    d["vol_ratio"] = np.where(d["vol20"] > 0, d["Volume"] / d["vol20"], np.nan)

    return d


def _score_row(r: pd.Series) -> float:
    """
    å…è²»/æ¨¡æ“¬æœŸï¼šç”¨å¯å›æº¯ã€å¯ç©©å®šçš„å› å­åšã€Œç›¸å°æ’åã€ã€‚
    Score ä¸ç”¨è¿½æ±‚é‡‘èå®Œç¾ï¼Œé‡é»æ˜¯ã€Œæ¯å¤©éƒ½èƒ½ç®—å‡ºå…¨å¸‚å ´ Top20ã€ã€‚
    """
    ma_bias = float(r.get("ma_bias_pct", np.nan))
    vol_ratio = float(r.get("vol_ratio", np.nan))
    ret_5d = float(r.get("ret_5d", np.nan))
    ret_20d = float(r.get("ret_20d", np.nan))

    # ç¼ºå€¼ä¿å®ˆè™•ç†ï¼ˆé¿å…äº‚çµ¦é«˜åˆ†ï¼‰
    if np.isnan(ma_bias):
        ma_bias = -999
    if np.isnan(vol_ratio):
        vol_ratio = 0
    if np.isnan(ret_5d):
        ret_5d = 0
    if np.isnan(ret_20d):
        ret_20d = 0

    # æ ¸å¿ƒï¼šè¶¨å‹¢ + é‡èƒ½ + å‹•èƒ½ï¼ˆæ¬Šé‡å¯èª¿ï¼‰
    # - ma_biasï¼š-10%~+10% å¸¸è¦‹ï¼Œæ”¾å¤§åˆ°å¯æ¯”è¼ƒ
    # - vol_ratioï¼š1.0=æ­£å¸¸ï¼Œ>1.2åæ”¾é‡
    # - ret_5d/20dï¼šå‹•èƒ½
    score = 0.0
    score += 0.55 * ma_bias
    score += 10.0 * np.tanh((vol_ratio - 1.0) * 1.5)   # é¿å…æ¥µç«¯é‡çˆ†æ‰
    score += 40.0 * ret_5d
    score += 20.0 * ret_20d

    # åŸºæœ¬é˜²è­·ï¼šæ¥µä½é‡ï¼ˆä¾‹å¦‚ vol_ratio < 0.2ï¼‰æ‰£åˆ†
    if vol_ratio < 0.2:
        score -= 8.0

    return float(score)


def _tag_row(r: pd.Series) -> str:
    ma_bias = float(r.get("ma_bias_pct", np.nan))
    vol_ratio = float(r.get("vol_ratio", np.nan))
    ret_5d = float(r.get("ret_5d", np.nan))

    # ç¼ºå€¼â†’è§€å¯Ÿ
    if np.isnan(ma_bias) or np.isnan(vol_ratio):
        return "â—‹è§€å¯Ÿ(è§€æœ›)"

    # ä½ åŸæœ¬çš„æ¨™ç±¤èªç³»ï¼ˆä¿æŒä¸€è‡´ï¼‰
    # ğŸ”¥ï¼šè¶¨å‹¢å¼· + æ”¾é‡
    if ma_bias >= 5 and vol_ratio >= 1.2:
        return "ğŸ”¥ä¸»åŠ›(è§€æœ›)"
    # èµ·æ¼²ï¼šå‰›ç¿»æ­£ã€ä¸”çŸ­ç·šå‹•èƒ½>0
    if ma_bias > 0 and ret_5d > 0:
        return "ğŸŸ¢èµ·æ¼²(è§€æœ›)"
    return "â—‹è§€å¯Ÿ(è§€æœ›)"


def run_analysis(
    df_market: pd.DataFrame,
    session: str = SESSION_EOD,
    cfg: Optional[AnalyzerConfig] = None
) -> Tuple[pd.DataFrame, Optional[str]]:
    """
    è¼¸å…¥ï¼šå…¨å¸‚å ´æ­·å²è³‡æ–™ï¼ˆDate, Symbol, Close, Volumeï¼‰
    è¼¸å‡ºï¼šTopN å¿«ç…§è¡¨ï¼ˆå« Score/Tag ç­‰ï¼‰
    """
    cfg = cfg or AnalyzerConfig()

    try:
        df = _ensure_columns(df_market)
        if df.empty:
            return pd.DataFrame(), "market dataframe is empty"

        df_feat = _calc_features(df, cfg)

        # å–æ¯æª”æœ€å¾Œä¸€ç­†ï¼ˆä»£è¡¨æœ€æ–°å¿«ç…§ï¼‰
        last = df_feat.sort_values(["Symbol", "Date"]).groupby("Symbol", as_index=False).tail(1).copy()

        # æ­·å²ä¸è¶³è€…å‰”é™¤
        hist_cnt = df.groupby("Symbol")["Date"].count()
        last["hist_cnt"] = last["Symbol"].map(hist_cnt).fillna(0).astype(int)
        last = last[last["hist_cnt"] >= cfg.min_history_days].copy()

        if last.empty:
            return pd.DataFrame(), f"no symbols meet min_history_days >= {cfg.min_history_days}"

        last["Score"] = last.apply(_score_row, axis=1)
        last["Tag"] = last.apply(_tag_row, axis=1)

        # çµ„å‡º TopN
        top = last.sort_values("Score", ascending=False).head(cfg.topn).copy()

        # æ•´ç†è¼¸å‡ºæ¬„ä½
        top_out = pd.DataFrame({
            "Date": top["Date"].dt.strftime("%Y-%m-%d"),
            "Symbol": top["Symbol"].astype(str),
            "Price": top["Close"].astype(float),
            "Volume": top["Volume"].astype(float),
            "MA_Bias": top["ma_bias_pct"].astype(float).round(2),
            "Vol_Ratio": top["vol_ratio"].astype(float).round(2),
            "Body_Power": 0.0,
            "Score": top["Score"].astype(float).round(1),
            "Tag": top["Tag"].astype(str),
        })

        return top_out.reset_index(drop=True), None

    except Exception as e:
        return pd.DataFrame(), f"{type(e).__name__}: {str(e)}"


def generate_ai_json(
    df_top: pd.DataFrame,
    market: str,
    session: str,
    macro_data: dict,
    name_map: Optional[Dict[str, str]] = None,
    account: Optional[dict] = None,
) -> str:
    """
    ç”¢å‡º Arbiter Input JSONï¼ˆä¿æŒä½ æ—¢æœ‰ V15.x æ ¼å¼ç¿’æ…£ï¼‰
    - Top20 + positions(å»é‡) çš„é‚è¼¯åœ¨ main.py åšï¼ˆé€™è£¡å‡è¨­ df_top å·²æ˜¯è¦è¼¸å‡ºçš„æ¸…å–®ï¼‰
    """
    import json
    from datetime import datetime

    name_map = name_map or {}
    account = account or {
        "cash_balance": 2_000_000,
        "total_equity": 2_000_000,
        "positions": []
    }

    # rankingï¼šä¾ df_top é †åºçµ¦ rank / tier / top20_flag
    stocks = []
    for i, r in df_top.reset_index(drop=True).iterrows():
        sym = str(r.get("Symbol"))
        price = float(r.get("Price", 0.0))
        score = float(r.get("Score", 0.0))
        tag = str(r.get("Tag", "â—‹è§€å¯Ÿ(è§€æœ›)"))

        rank = int(i + 1)
        tier = "A" if rank <= 10 else "B"
        top20_flag = True if rank <= 20 else False

        # ä¸­æ–‡åï¼šå„ªå…ˆæœ¬åœ°æ˜ å°„
        name = name_map.get(sym, sym)

        stocks.append({
            "Symbol": sym,
            "Name": name,
            "Price": price,
            "ranking": {
                "symbol": sym,
                "rank": rank,
                "tier": tier,
                "top20_flag": top20_flag
            },
            "Technical": {
                "MA_Bias": float(r.get("MA_Bias", 0.0)),
                "Vol_Ratio": float(r.get("Vol_Ratio", 0.0)),
                "Body_Power": float(r.get("Body_Power", 0.0)),
                "Score": score,
                "Tag": tag
            },
            # å…è²»/æ¨¡æ“¬æœŸï¼šæ³•äººå…ˆå…è¨± UNAVAILABLEï¼Œä¸è¦è®“ç³»çµ±çˆ†æ‰
            "Institutional": {
                "Inst_Visual": "PENDING",
                "Inst_Net_3d": 0.0,
                "Inst_Streak3": 0,
                "Inst_Dir3": "PENDING",
                "Inst_Status": "PENDING"
            },
            "Structure": {
                "OPM": 0.0,
                "Rev_Growth": 0.0,
                "PE": 0.0,
                "Sector": "Unknown",
                "Rev_Growth_Source": "raw"
            },
            "risk": {
                "position_pct_max": 12,
                "risk_per_trade_max": 1.0,
                "trial_flag": True
            },
            "orphan_holding": False,
            "weaken_flags": {
                "technical_weaken": False,
                "structure_weaken": False
            }
        })

    payload = {
        "meta": {
            "system": "Predator V15.7 (SIM/FREE)",
            "market": market,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "session": session
        },
        "macro": macro_data,
        "account": account,
        "stocks": stocks
    }

    return json.dumps(payload, ensure_ascii=False, indent=2)
