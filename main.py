# main.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
from datetime import datetime

import pandas as pd
import streamlit as st

from analyzer import run_analysis, generate_ai_json, SESSION_INTRADAY, SESSION_EOD
from finmind_institutional import fetch_finmind_institutional
from institutional_utils import calc_inst_3d

# âœ… æ–°å¢ï¼šå…¨å¸‚å ´æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚+ä¸Šæ«ƒï¼‰èˆ‡ç›¤ä¸­é‡èƒ½æ­£è¦åŒ–
from market_amount import fetch_amount_total, intraday_norm


# =========================
# 0) èˆªé‹è‚¡ä¼°å€¼ï¼ˆæ‰‹å‹•è¦†è“‹å±¤ï¼‰
# =========================
SHIPPING_VALUATION = {
    "2603.TW": {
        "name_zh": "é•·æ¦®",
        "sector": "èˆªé‹",
        "opm_q": 22.73,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 41.92,
        "price_ref": 192.54,
        "price_ref_date": "2026-01-22",
        "pe_calc": 4.59,
        "label": "ğŸŸ¢ æ¥µåº¦ä½ä¼° (Deep Value)",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
    "2609.TW": {
        "name_zh": "é™½æ˜",
        "sector": "èˆªé‹",
        "opm_q": 10.49,
        "opm_q_period": "2025 Q3",
        "eps_ttm": 7.83,
        "price_ref": 55.57,
        "price_ref_date": "2026-01-22",
        "pe_calc": 7.09,
        "label": "ğŸŸ¡",
        "source": "è²¡å ±ç‹—/ç©è‚¡ç¶²ï¼ˆæœ€æ–°å­£å ±è³‡æ–™åº«ï¼‰",
    },
}


# =========================
# Utils
# =========================
def _fmt_date(dt) -> str:
    try:
        return pd.to_datetime(dt).strftime("%Y-%m-%d")
    except Exception:
        return datetime.now().strftime("%Y-%m-%d")


def _find_existing_path(candidates: list[str]) -> str | None:
    for p in candidates:
        if os.path.exists(p):
            return p
    return None


def _load_market_csv(market: str) -> pd.DataFrame:
    """
    ä½ çš„ repo ç›®å‰å¯èƒ½å‡ºç¾ï¼š
      - data_tw-share.csv / data_tw.csvï¼ˆæ”¾åœ¨æ ¹ç›®éŒ„ï¼‰
      - data/data_tw-share.csv / data/data_tw.csvï¼ˆæ”¾åœ¨ data/ ç›®éŒ„ï¼‰
    """
    fname = f"data_{market}.csv"
    candidates = [
        fname,
        os.path.join("data", fname),
        "data_tw-share.csv",
        os.path.join("data", "data_tw-share.csv"),
        "data_tw.csv",
        os.path.join("data", "data_tw.csv"),
    ]
    hit = _find_existing_path(candidates)
    if not hit:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™æª”ï¼š{fname} / data_tw-share.csv / data_tw.csvï¼ˆæˆ– data/ ç›®éŒ„ä¸‹ï¼‰")
    return pd.read_csv(hit)


def _apply_shipping_valuation_overrides(df_top: pd.DataFrame) -> pd.DataFrame:
    """
    èˆªé‹ä¼°å€¼ overlayï¼š
    - ä¸æ±¡æŸ“åŸæœ¬ yfinance çš„ Structure æ¬„ä½
    - æ–°å¢ Valuation_Overrideï¼ˆdictï¼‰
    - è£œ Nameï¼ˆä¸­æ–‡åï¼‰
    """
    out = df_top.copy()

    def _inject(row: pd.Series) -> pd.Series:
        sym = str(row.get("Symbol", "")).strip()
        info = SHIPPING_VALUATION.get(sym)
        if not info:
            return row

        if not row.get("Name"):
            row["Name"] = info.get("name_zh", sym)

        row["Valuation_Override"] = {
            "sector": info.get("sector"),
            "opm_q": float(info.get("opm_q", 0.0)),
            "opm_q_period": info.get("opm_q_period"),
            "eps_ttm": float(info.get("eps_ttm", 0.0)),
            "price_ref": float(info.get("price_ref", 0.0)),
            "price_ref_date": info.get("price_ref_date"),
            "pe_calc": float(info.get("pe_calc", 0.0)),
            "label": info.get("label"),
            "source": info.get("source"),
        }
        return row

    return out.apply(_inject, axis=1)


def _merge_institutional_into_df_top(df_top: pd.DataFrame, inst_df: pd.DataFrame, trade_date: str) -> pd.DataFrame:
    """
    æŠŠ calc_inst_3d çš„çµæœå¡å› df_top çš„ Institutional æ¬„ä½ï¼ˆdictï¼‰
    """
    df_out = df_top.copy()
    inst_map: dict[str, dict] = {}

    for _, r in df_out.iterrows():
        symbol = str(r.get("Symbol", ""))
        inst_calc = calc_inst_3d(inst_df, symbol=symbol, trade_date=trade_date)
        inst_map[symbol] = {
            "Inst_Visual": inst_calc.get("Inst_Status", "PENDING"),
            "Inst_Net_3d": float(inst_calc.get("Inst_Net_3d", 0.0)),
            "Inst_Streak3": int(inst_calc.get("Inst_Streak3", 0)),
            "Inst_Dir3": inst_calc.get("Inst_Dir3", "PENDING"),
            "Inst_Status": inst_calc.get("Inst_Status", "PENDING"),
        }

    df_out["Institutional"] = df_out["Symbol"].astype(str).map(inst_map)
    return df_out


def _decide_inst_status(inst_df: pd.DataFrame, symbols: list[str], trade_date: str) -> tuple[str, list[str]]:
    """
    macro.overview.inst_status + inst_dates_3d
    è¦å‰‡ï¼šåªè¦æœ‰ä»»ä½•ä¸€æª”èƒ½æ»¿è¶³ã€Œä¸‰æ—¥è³‡æ–™é½Šå…¨ã€â†’ READYï¼›å¦å‰‡ PENDING
    """
    ready_any = False
    dates_3d: list[str] = []

    for sym in symbols:
        r = calc_inst_3d(inst_df, symbol=sym, trade_date=trade_date)
        if r.get("Inst_Status") == "READY":
            ready_any = True

    try:
        if not inst_df.empty and "date" in inst_df.columns:
            dates_3d = sorted(inst_df["date"].astype(str).unique().tolist())[-3:]
    except Exception:
        dates_3d = []

    return ("READY" if ready_any else "PENDING"), dates_3d


def _load_avg20_amount_total(trade_date: str) -> int | None:
    """
    è®€å–ä½ è‡ªå·±è½åœ°çš„å¸‚å ´æˆäº¤é‡‘é¡æ­·å²æª”ï¼ˆå»ºè­°ä½ å¾ŒçºŒå›ºå®šå»ºç«‹ï¼‰ï¼š
      data/tw_market_turnover.csv
    æ¬„ä½å»ºè­°ï¼š
      date, amount_total
    é€™è£¡å›å‚³è¿‘ 20 æ—¥ä¸­ä½æ•¸ï¼ˆæ›´æŠ—æ¥µç«¯å€¼ï¼‰ï¼Œè‹¥ä¸è¶³å°±å›å‚³ Noneã€‚
    """
    candidates = [
        os.path.join("data", "tw_market_turnover.csv"),
        "tw_market_turnover.csv",
    ]
    fp = _find_existing_path(candidates)
    if not fp:
        return None

    try:
        d = pd.read_csv(fp)
        if "date" not in d.columns or "amount_total" not in d.columns:
            return None

        d["date"] = pd.to_datetime(d["date"], errors="coerce")
        d["amount_total"] = pd.to_numeric(d["amount_total"], errors="coerce")
        d = d.dropna(subset=["date", "amount_total"]).sort_values("date")

        td = pd.to_datetime(trade_date, errors="coerce")
        if pd.isna(td):
            return None

        d = d[d["date"] <= td].tail(20)
        if len(d) < 10:
            return None

        return int(d["amount_total"].median())
    except Exception:
        return None


def generate_market_comment_retail(macro_overview: dict) -> str:
    """
    ä¾æ“š Macro Overview è‡ªå‹•ç”Ÿæˆã€Œä»Šæ—¥å¸‚å ´ç‹€æ…‹åˆ¤æ–·ã€ï¼ˆä¸€èˆ¬æŠ•è³‡äººå¯è®€ç‰ˆï¼‰
    æ³¨æ„ï¼šä½ å·²è¦ç¯„ market_comment åƒ…ä¾›äººé¡é–±è®€ï¼ŒArbiter å¿…é ˆå¿½ç•¥ã€‚
    """
    amount_total = macro_overview.get("amount_total")
    inst_status = macro_overview.get("inst_status", "PENDING")
    degraded_mode = bool(macro_overview.get("degraded_mode", False))
    kill_switch = bool(macro_overview.get("kill_switch", False))
    v14_watch = bool(macro_overview.get("v14_watch", False))

    if kill_switch or v14_watch:
        return "ä»Šæ—¥å¸‚å ´ä¸ç¢ºå®šæ€§åé«˜ï¼Œç³»çµ±å·²å•Ÿå‹•é¢¨æ§ä¿è­·ï¼ˆç¦æ­¢é€²å ´ï¼‰ï¼Œå»ºè­°ä»¥è³‡é‡‘ä¿å…¨ç‚ºå„ªå…ˆã€‚"

    # æˆäº¤é‡‘é¡ï¼ˆä»¥ã€Œä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆã€ç‚ºä¸»ï¼‰
    amount_num = None
    try:
        if isinstance(amount_total, str) and amount_total not in ("å¾…æ›´æ–°", "", None):
            amount_num = float(amount_total.replace(",", ""))
        elif isinstance(amount_total, (int, float)):
            amount_num = float(amount_total)
    except Exception:
        amount_num = None

    # é‡èƒ½æ–‡å­—ï¼ˆä¸å†ç”¨å›ºå®š 3000å„„é–€æª»ï¼Œè€Œæ˜¯åå‘ã€Œæè¿° + ç›¤ä¸­æ­£è¦åŒ–æç¤ºã€ï¼‰
    liquidity_text = "æˆäº¤é‡‘é¡å¾…æ›´æ–°ï¼Œ" if amount_num is None else "æˆäº¤é‡‘é¡åä½ï¼Œ"
    if amount_num is not None:
        amount_eok = amount_num / 100_000_000  # å…ƒâ†’å„„
        liquidity_text = f"{liquidity_text}ï¼ˆæˆäº¤é‡‘é¡ç´„ {amount_eok:,.0f} å„„ï¼‰"

    # æ³•äººç‹€æ…‹
    if inst_status in ("UNAVAILABLE", "PENDING"):
        inst_text = "æ³•äººè³‡æ–™å°šä¸è¶³ä»¥åˆ¤è®€æ–¹å‘ï¼Œå»ºè­°ä»¥è§€å¯Ÿæˆ–å°é¡è©¦å–®ç‚ºä¸»ï¼Œä¸å®œè²¿ç„¶é‡å€‰ã€‚"
    elif inst_status == "READY":
        inst_text = "æ³•äººè³‡æ–™å¯ç”¨ï¼Œä½†ä»éœ€ä»¥å€‹è‚¡æ¢ä»¶èˆ‡é¢¨æ§è¦å‰‡ç‚ºä¸»ã€‚"
    else:
        inst_text = "æ³•äººè³‡æ–™ç‹€æ…‹ä¸å®Œæ•´ï¼Œå»ºè­°å¯©æ…æ‡‰å°ã€‚"

    # é™ç´šèªªæ˜
    strategy_text = "æ•´é«”ç­–ç•¥ä»¥ä¿å®ˆç‚ºä¸»ã€‚" if degraded_mode else "å€‰ä½å¯ä¾å€‹è‚¡è¨Šè™Ÿå½ˆæ€§èª¿æ•´ã€‚"

    # è‹¥æœ‰ç›¤ä¸­æ­£è¦åŒ–ï¼ˆæä¾›æç¤ºä½†ä¸ä¸‹çµè«–ï¼‰
    norm = macro_overview.get("amount_norm")
    norm_hint = ""
    if isinstance(norm, dict):
        cum_ratio = norm.get("amount_norm_cum_ratio")
        label = norm.get("amount_norm_label")
        if cum_ratio is not None and label in ("LOW", "NORMAL", "HIGH"):
            norm_hint = f"ï¼ˆç›¤ä¸­é‡èƒ½æ­£è¦åŒ–ï¼š{label}ï¼Œç´¯ç©æ¯”ç‡â‰ˆ{cum_ratio}ï¼‰"

    return liquidity_text + inst_text + strategy_text + norm_hint


# =========================
# App
# =========================
def app():
    st.set_page_config(page_title="Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°", layout="wide")
    st.title("Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°")

    market = st.sidebar.selectbox("Market", ["tw-share", "tw"], index=0)
    session = st.sidebar.selectbox("Session", [SESSION_INTRADAY, SESSION_EOD], index=0)
    run_btn = st.sidebar.button("Run")

    if not run_btn:
        st.info("æŒ‰å·¦å´ Run ç”¢ç”Ÿ Top æ¸…å–®èˆ‡ JSONã€‚")
        return

    # 1) Load market dataï¼ˆå€‹è‚¡æ± è³‡æ–™ï¼Œç”¨æ–¼é¸è‚¡çŸ©é™£/æŠ€è¡“åˆ†æ•¸ï¼‰
    df = _load_market_csv(market)
    df["Date"] = pd.to_datetime(df["Date"], errors="coerce")
    latest_date = df["Date"].max()
    trade_date = _fmt_date(latest_date)

    # 2) Run analyzerï¼ˆç”¢ç”Ÿ Top æ¸…å–®ï¼‰
    df_top, err = run_analysis(df, session=session)
    if err:
        st.error(f"Analyzer error: {err}")
        return

    # 2.1) èˆªé‹ä¼°å€¼ overlay
    df_top = _apply_shipping_valuation_overrides(df_top)

    # 3) Fetch institutional (FinMind)
    start_date = (pd.to_datetime(trade_date) - pd.Timedelta(days=45)).strftime("%Y-%m-%d")
    end_date = trade_date
    symbols = df_top["Symbol"].astype(str).tolist()

    inst_fetch_error = None
    try:
        inst_df = fetch_finmind_institutional(
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            token=os.getenv("FINMIND_TOKEN", None),
        )
    except Exception as e:
        inst_df = pd.DataFrame(columns=["date", "symbol", "net_amount"])
        inst_fetch_error = f"{type(e).__name__}: {str(e)}"
        st.warning(f"å€‹è‚¡æ³•äººè³‡æ–™æŠ“å–å¤±æ•—ï¼š{inst_fetch_error}")

    # 4) Determine macro inst_status + inst_dates_3d
    inst_status, inst_dates_3d = _decide_inst_status(inst_df, symbols, trade_date)

    # è‹¥ API ä»˜è²»/ä¸å¯ç”¨ï¼ˆå¸¸è¦‹ 402ï¼‰ï¼Œç›´æ¥æ¨™è¨˜ UNAVAILABLE
    if inst_fetch_error and ("402" in inst_fetch_error or "Payment Required" in inst_fetch_error):
        inst_status = "UNAVAILABLE"
        inst_dates_3d = []

    # 5) Merge institutional into df_top
    df_top2 = _merge_institutional_into_df_top(df_top, inst_df, trade_date=trade_date)

    # 6) âœ… å…¨å¸‚å ´æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆï¼‰+ ç›¤ä¸­é‡èƒ½æ­£è¦åŒ–
    amount_err = None
    amount_twse = amount_tpex = amount_total = None
    src_twse = src_tpex = None

    try:
        amt = fetch_amount_total()
        amount_twse = amt.amount_twse
        amount_tpex = amt.amount_tpex
        amount_total = amt.amount_total
        src_twse = amt.source_twse
        src_tpex = amt.source_tpex
    except Exception as e:
        amount_err = f"{type(e).__name__}: {e}"
        st.warning(f"å…¨å¸‚å ´æˆäº¤é‡‘é¡æŠ“å–å¤±æ•—ï¼ˆamount_total æœƒé¡¯ç¤ºå¾…æ›´æ–°ï¼‰ï¼š{amount_err}")

    # 6.1) è®€å–è¿‘20æ—¥åŸºæº–ï¼ˆå»ºè­°ä½ å¾ŒçºŒå›ºå®šè½åœ° tw_market_turnover.csvï¼‰
    avg20_amount_total = _load_avg20_amount_total(trade_date)

    # 6.2) è¨˜ä½ä¸Šä¸€ç­† amount_totalï¼Œä¾›ã€Œä¿å®ˆå‹åˆ‡ç‰‡é‡ã€ç”¨ï¼ˆæ­¤è™•ä»¥ã€æ¯æ¬¡ Runã€ç‚ºä¸€ç­†ï¼‰
    prev_key = "amount_total_prev_int"
    amount_total_prev = st.session_state.get(prev_key)

    norm = None
    if isinstance(amount_total, int) and amount_total > 0 and isinstance(avg20_amount_total, int) and avg20_amount_total > 0:
        norm = intraday_norm(
            amount_total_now=amount_total,
            amount_total_prev=amount_total_prev,
            avg20_amount_total=avg20_amount_total,
        )

    if isinstance(amount_total, int):
        st.session_state[prev_key] = amount_total

    # 7) macro_overviewï¼ˆæ³¨æ„ï¼šamount_total æ‰æ˜¯ã€Œå¸‚å ´æˆäº¤é‡‘é¡å£å¾‘ã€ï¼‰
    degraded_mode = (inst_status == "PENDING")  # UNAVAILABLE ä¸å¼·åˆ¶ degradedï¼ˆäº¤çµ¦ Arbiter è¦å‰‡ï¼‰

    macro_overview = {
        "amount_twse": f"{amount_twse:,}" if isinstance(amount_twse, int) else "å¾…æ›´æ–°",
        "amount_tpex": f"{amount_tpex:,}" if isinstance(amount_tpex, int) else "å¾…æ›´æ–°",
        "amount_total": f"{amount_total:,}" if isinstance(amount_total, int) else "å¾…æ›´æ–°",
        "amount_sources": {
            "twse": src_twse,
            "tpex": src_tpex,
            "error": amount_err,
        },
        "avg20_amount_total_median": f"{avg20_amount_total:,}" if isinstance(avg20_amount_total, int) else None,
        "inst_net": "A:0.00å„„ | B:0.00å„„",
        "trade_date": trade_date,
        "inst_status": inst_status,
        "inst_dates_3d": inst_dates_3d,
        "kill_switch": False,
        "v14_watch": False,
        "degraded_mode": degraded_mode,
        "data_mode": "INTRADAY" if session == SESSION_INTRADAY else "EOD",
    }

    if norm:
        macro_overview["amount_norm"] = norm

    # 8) ç”¢ç”Ÿå¸‚å ´ä¸€å¥è©±ï¼ˆåƒ…ä¾›äººé¡é–±è®€ï¼›Arbiter å¿…é ˆå¿½ç•¥ market_commentï¼‰
    market_comment = generate_market_comment_retail(macro_overview)
    macro_overview["market_comment"] = market_comment

    macro_data = {
        "overview": macro_overview,
        "indices": [],
    }

    # 9) Generate JSON for Arbiter
    json_text = generate_ai_json(df_top2, market=market, session=session, macro_data=macro_data)

    # =========================
    # UI
    # =========================
    st.subheader("å…¨å¸‚å ´æˆäº¤é‡‘é¡ï¼ˆä¸Šå¸‚+ä¸Šæ«ƒåˆè¨ˆï¼‰")
    col1, col2, col3 = st.columns(3)
    col1.metric("ä¸Šå¸‚ TWSE æˆäº¤é‡‘é¡(å…ƒ)", macro_overview["amount_twse"])
    col2.metric("ä¸Šæ«ƒ TPEx æˆäº¤é‡‘é¡(å…ƒ)", macro_overview["amount_tpex"])
    col3.metric("åˆè¨ˆ amount_total(å…ƒ)", macro_overview["amount_total"])

    with st.expander("æˆäº¤é‡‘é¡ä¾†æºèˆ‡é™¤éŒ¯è³‡è¨Š"):
        st.write(macro_overview.get("amount_sources", {}))
        st.write({"avg20_amount_total_median": macro_overview.get("avg20_amount_total_median")})
        st.write({"amount_norm": macro_overview.get("amount_norm")})

    st.subheader("ä»Šæ—¥å¸‚å ´ç‹€æ…‹åˆ¤æ–·ï¼ˆä¸€èˆ¬æŠ•è³‡äººç‰ˆï¼›åƒ…ä¾›é–±è®€ï¼‰")
    st.info(market_comment)

    # èˆªé‹ä¼°å€¼å¡ï¼ˆåªé¡¯ç¤ºå‘½ä¸­è€…ï¼‰
    hit = df_top2[df_top2["Symbol"].isin(list(SHIPPING_VALUATION.keys()))].copy()
    if not hit.empty:
        st.subheader("èˆªé‹è‚¡ä¼°å€¼å¿«ç…§ï¼ˆè²¡å ±ç‹—/ç©è‚¡ç¶²ï¼‰")
        cols = ["Symbol", "Name", "Valuation_Override"]
        show = hit[cols].copy()

        def _render(v: dict) -> str:
            if not isinstance(v, dict):
                return ""
            return (
                f"OPM({v.get('opm_q_period')}): {v.get('opm_q')}% | "
                f"EPS(TTM): {v.get('eps_ttm')} | "
                f"Price({v.get('price_ref_date')}): {v.get('price_ref')} | "
                f"PEâ‰ˆ{v.get('pe_calc')} | {v.get('label')} | "
                f"ä¾†æº: {v.get('source')}"
            )

        show["ä¼°å€¼æ‘˜è¦"] = show["Valuation_Override"].apply(_render)
        st.dataframe(show[["Symbol", "Name", "ä¼°å€¼æ‘˜è¦"]], use_container_width=True)

    st.subheader("Top List")
    st.dataframe(df_top2, use_container_width=True)

    st.subheader("AI JSON (Arbiter Input)")
    st.code(json_text, language="json")

    # optional: save
    outname = f"ai_payload_{market}_{trade_date.replace('-', '')}_{session.lower()}.json"
    with open(outname, "w", encoding="utf-8") as f:
        f.write(json_text)
    st.success(f"JSON å·²è¼¸å‡ºï¼š{outname}")


if __name__ == "__main__":
    app()
