# main.py
# -*- coding: utf-8 -*-
from __future__ import annotations

import os
import glob
import json
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import yfinance as yf

# åª import ä½  market_amount.py å…§ç¢ºå¯¦å­˜åœ¨çš„åç¨±
from market_amount import TZ_TAIPEI, fetch_amount_total, intraday_norm


APP_TITLE = "Sunheroï½œè‚¡å¸‚æ™ºèƒ½è¶…ç›¤ä¸­æ§å°"
SYSTEM_NAME = "Predator V15.7ï¼ˆFree/Simï¼‰"


# ====== åŸºç¤å·¥å…· ======
def now_taipei() -> datetime:
    return datetime.now(tz=TZ_TAIPEI)


def safe_float(x, default=0.0) -> float:
    try:
        if x is None:
            return default
        if isinstance(x, (float, int, np.floating, np.integer)):
            return float(x)
        s = str(x).strip()
        if s == "" or s.lower() in ("none", "nan"):
            return default
        return float(s)
    except Exception:
        return default


def to_bn_twd(amount_int: Optional[int]) -> Optional[float]:
    """å…ƒ -> å„„ï¼ˆ1e8ï¼‰"""
    if amount_int is None:
        return None
    try:
        return round(float(amount_int) / 1e8, 2)
    except Exception:
        return None


def fmt_bn(x: Optional[float]) -> str:
    if x is None or (isinstance(x, float) and np.isnan(x)):
        return "å¾…æ›´æ–°"
    return f"{x:,.2f} å„„"


def _normalize_symbol(s: str) -> str:
    s = (s or "").strip().upper()
    # å…è¨±ä½¿ç”¨è€…è¼¸å…¥ 2330 ä¹Ÿèƒ½è‡ªå‹•è£œ .TW
    if s.isdigit():
        return f"{s}.TW"
    return s


# ====== è‚¡ç¥¨ä¸­æ–‡åç¨±ï¼ˆæœ€å°å¯ç”¨ç‰ˆï¼‰=====
# ä½ å¯è‡ªè¡Œæ“´å……ï¼›æˆ–æœªä¾†æ”¹ç‚ºè®€å–ä¸€ä»½ data/tw_names.csv
TW_NAME_MAP = {
    "2330.TW": "å°ç©é›»",
    "2317.TW": "é´»æµ·",
    "2382.TW": "å»£é”",
    "2454.TW": "è¯ç™¼ç§‘",
    "2308.TW": "å°é”é›»",
    "2603.TW": "é•·æ¦®",
    "2609.TW": "é™½æ˜",
    "3231.TW": "ç·¯å‰µ",
    "0050.TW": "å…ƒå¤§å°ç£50",
}


def symbol_to_name(sym: str) -> str:
    return TW_NAME_MAP.get(sym, "")


# ====== è®€å–å°è‚¡è³‡æ–™ï¼ˆTop20 Universeï¼‰=====
def _find_candidate_csv_files(market: str) -> List[str]:
    """
    ä½ çš„ repo å¯èƒ½å­˜åœ¨å¤šç¨®å‘½åï¼š
    - data/data_tw-share.csv
    - data_tw-share.csv
    - data_tw.csv
    - data/data_tw.csv
    é€™è£¡éƒ½æœƒæ‰¾ï¼Œä¸¦æŒ‘æœ€æ–°æª”ã€‚
    """
    patterns = [
        f"data/data_{market}.csv",
        f"data/data-{market}.csv",
        f"data/data_{market.replace('-', '_')}.csv",
        f"data/data_{market.replace('_', '-')}.csv",
        f"data_{market}.csv",
        f"data-{market}.csv",
        "data/data_tw.csv",
        "data_tw.csv",
        "data/data-tw.csv",
        "data-tw.csv",
        "data/tw-share.csv",
        "tw-share.csv",
    ]
    files = []
    for p in patterns:
        files.extend(glob.glob(p))
    # å»é‡
    files = sorted(list(set(files)))
    return files


def _pick_latest_file(files: List[str]) -> Optional[str]:
    if not files:
        return None
    files_sorted = sorted(files, key=lambda f: os.path.getmtime(f), reverse=True)
    return files_sorted[0]


def load_market_df(market: str) -> pd.DataFrame:
    files = _find_candidate_csv_files(market)
    latest = _pick_latest_file(files)
    if not latest:
        raise FileNotFoundError(
            f"æ‰¾ä¸åˆ° {market} çš„è³‡æ–™æª”ã€‚å·²å˜—è©¦ï¼šdata/data_{market}.csvã€data_{market}.csvã€data_tw.csv ç­‰å¸¸è¦‹å‘½åã€‚"
        )

    df = pd.read_csv(latest)

    # æ¬„ä½æ¨™æº–åŒ–ï¼ˆå…¼å®¹ä½ ä¸åŒç‰ˆæœ¬è¼¸å‡ºï¼‰
    # å¿…è¦æ¬„ä½ï¼šDate / Symbol / Close / Volume
    col_map = {}
    for c in df.columns:
        lc = c.strip().lower()
        if lc == "date":
            col_map[c] = "Date"
        elif lc in ("symbol", "ticker", "code"):
            col_map[c] = "Symbol"
        elif lc in ("close", "adj close", "adj_close"):
            col_map[c] = "Close"
        elif lc in ("volume",):
            col_map[c] = "Volume"
        elif lc in ("open",):
            col_map[c] = "Open"
        elif lc in ("high",):
            col_map[c] = "High"
        elif lc in ("low",):
            col_map[c] = "Low"
        elif lc in ("vol_ratio", "volume_ratio"):
            col_map[c] = "Vol_Ratio"
        elif lc in ("ma_bias", "ma_bias_pct", "bias_pct"):
            col_map[c] = "MA_Bias"
        elif lc in ("score",):
            col_map[c] = "Score"
        elif lc in ("ret20_pct", "ret_20", "ret20"):
            col_map[c] = "ret20_pct"

    df = df.rename(columns=col_map)

    # Date è½‰ datetime
    if "Date" in df.columns:
        df["Date"] = pd.to_datetime(df["Date"], errors="coerce")

    # Symbol çµ±ä¸€æ ¼å¼ï¼š2330.TW
    if "Symbol" in df.columns:
        df["Symbol"] = df["Symbol"].astype(str).map(_normalize_symbol)

    # è£œ name
    if "Name" not in df.columns:
        df["Name"] = df["Symbol"].map(symbol_to_name)

    # è‹¥ Score ä¸å­˜åœ¨ï¼Œåšä¸€å€‹æœ€å°å¯ç”¨çš„æ›¿ä»£åˆ†æ•¸ï¼ˆåƒ…ä¾›æ’åºï¼ŒéæŠ•è³‡å»ºè­°ï¼‰
    if "Score" not in df.columns:
        # å¯ç”¨æ¬„ä½ï¼šret20_pct / Vol_Ratio / MA_Bias
        r20 = df["ret20_pct"] if "ret20_pct" in df.columns else 0.0
        vr = df["Vol_Ratio"] if "Vol_Ratio" in df.columns else 1.0
        mb = df["MA_Bias"] if "MA_Bias" in df.columns else 0.0

        df["Score"] = (
            pd.to_numeric(r20, errors="coerce").fillna(0.0) * 0.7
            + pd.to_numeric(vr, errors="coerce").fillna(1.0) * 20.0
            + pd.to_numeric(mb, errors="coerce").fillna(0.0) * 0.8
        )

    return df


def latest_trade_date(df: pd.DataFrame) -> Optional[pd.Timestamp]:
    if "Date" not in df.columns:
        return None
    d = df["Date"].dropna()
    if d.empty:
        return None
    return d.max().normalize()


def build_top20(df: pd.DataFrame, trade_date: pd.Timestamp) -> pd.DataFrame:
    sub = df[df["Date"].dt.normalize() == trade_date].copy()
    if sub.empty:
        return sub

    # æ¬„ä½è£œé½Š
    for c in ["Close", "Volume", "Open", "High", "Low", "Vol_Ratio", "MA_Bias", "Score"]:
        if c not in sub.columns:
            sub[c] = np.nan

    # æ’åºï¼šScore é«˜è€…åœ¨å‰
    sub = sub.sort_values("Score", ascending=False).reset_index(drop=True)
    sub["Rank"] = np.arange(1, len(sub) + 1)
    top = sub.head(20).copy()
    return top


# ====== åœ‹éš›å¸‚å ´ï¼ˆç¾è‚¡/åŒ¯ç‡ï¼‰=====
@dataclass
class GlobalRow:
    name: str
    symbol: str
    date: str
    close: float
    chg_pct: float


def fetch_yf_last_close(symbol: str, period_days: int = 10) -> Optional[Tuple[pd.Timestamp, float, float]]:
    """
    æŠ“å–ã€Œæœ€æ–°å¯ç”¨äº¤æ˜“æ—¥ã€æ”¶ç›¤åƒ¹èˆ‡æ—¥è®Šå‹•ç™¾åˆ†æ¯”
    å›å‚³ï¼š(date, close, chg_pct)
    """
    try:
        df = yf.download(symbol, period=f"{period_days}d", interval="1d", progress=False, auto_adjust=False)
        if df is None or df.empty:
            return None
        df = df.dropna(subset=["Close"])
        if df.empty:
            return None
        last = df.iloc[-1]
        last_date = pd.to_datetime(df.index[-1]).normalize()
        last_close = float(last["Close"])
        if len(df) >= 2:
            prev_close = float(df.iloc[-2]["Close"])
            chg_pct = 0.0 if prev_close == 0 else (last_close / prev_close - 1.0) * 100.0
        else:
            chg_pct = 0.0
        return last_date, last_close, chg_pct
    except Exception:
        return None


def build_global_tables() -> Tuple[pd.DataFrame, pd.DataFrame]:
    us_items = [
        ("S&P500", "^GSPC"),
        ("NASDAQ", "^IXIC"),
        ("DOW", "^DJI"),
        ("SOX", "^SOX"),
        ("VIX", "^VIX"),
    ]
    fx_items = [
        ("USD/JPY", "JPY=X"),
        ("USD/TWD", "TWD=X"),
    ]

    us_rows: List[Dict] = []
    for name, sym in us_items:
        got = fetch_yf_last_close(sym, period_days=15)
        if not got:
            us_rows.append({"Name": name, "Symbol": sym, "Date": "N/A", "Close": np.nan, "Chg%": np.nan})
        else:
            d, close, chg = got
            us_rows.append({"Name": name, "Symbol": sym, "Date": str(d.date()), "Close": close, "Chg%": round(chg, 2)})

    fx_rows: List[Dict] = []
    for name, sym in fx_items:
        got = fetch_yf_last_close(sym, period_days=15)
        if not got:
            fx_rows.append({"Name": name, "Symbol": sym, "Date": "N/A", "Close": np.nan, "Chg%": np.nan})
        else:
            d, close, chg = got
            fx_rows.append({"Name": name, "Symbol": sym, "Date": str(d.date()), "Close": close, "Chg%": round(chg, 2)})

    us_df = pd.DataFrame(us_rows)
    fx_df = pd.DataFrame(fx_rows)
    return us_df, fx_df


# ====== æˆäº¤é‡‘é¡ï¼ˆå®˜æ–¹å£å¾‘ï¼‰=====
def fetch_official_amount(verify_ssl: bool = True) -> Dict:
    """
    ä½¿ç”¨ market_amount.py çš„ fetch_amount_total()
    - è‹¥ TPEx æŠ“ä¸åˆ°ï¼šå›å‚³ç¼ºå£ warningï¼Œä½† UI ä¸å´©æ½°
    """
    out = {
        "trade_date": None,
        "amount_twse": None,
        "amount_tpex": None,
        "amount_total": None,
        "sources": {"twse": None, "tpex": None},
        "warning": None,
        "error": None,
    }

    try:
        # market_amount.py æœ¬èº«ä½¿ç”¨ requests.get(..., timeout=15) ä¸¦æœªæš´éœ² verify åƒæ•¸
        # Streamlit Cloud è‹¥é‡åˆ°æ†‘è­‰å•é¡Œï¼Œå»ºè­°åœ¨ market_amount.py å…§åŠ  verify=verify_ssl
        # é€™è£¡å…ˆä»¥ UI æé†’ï¼›ä¸å¼·è¡Œç¹éï¼ˆé¿å…æŠŠå®‰å…¨é™ç´šé»˜èªåŒ–ï¼‰ã€‚
        ma = fetch_amount_total()
        out["amount_twse"] = ma.amount_twse
        out["amount_tpex"] = ma.amount_tpex
        out["amount_total"] = ma.amount_total
        out["sources"]["twse"] = ma.source_twse
        out["sources"]["tpex"] = ma.source_tpex
        out["trade_date"] = str(now_taipei().date())
    except Exception as e:
        out["error"] = str(e)

    return out


# ====== Arbiter Inputï¼ˆFree/Simï¼‰=====
def decide_inst_status_free() -> Tuple[str, List[str]]:
    """
    å…è²»/æ¨¡æ“¬æœŸï¼šä¸ä½¿ç”¨ FinMindï¼ˆé¿å… 402ï¼‰
    æ‰€ä»¥ inst_status æ°¸é ä¸æ˜¯ READYï¼Œé™¤éä½ æœªä¾†æ”¹ç”¨å…¶ä»–å…è²»ä¾†æºã€‚
    """
    return "UNAVAILABLE", []


def decide_degraded_mode(amount_total: Optional[int], inst_status: str) -> bool:
    # çµ•å°é˜²ç·šï¼šä»»ä¸€é—œéµè³‡æ–™ç¼ºå¤± => degraded_mode = True
    if amount_total is None or amount_total <= 0:
        return True
    if inst_status != "READY":
        return True
    return False


def build_market_comment(
    amount_total: Optional[int],
    inst_status: str,
    degraded_mode: bool,
    data_mode: str,
    amount_sources: Dict,
) -> str:
    msgs = []
    if amount_total is None or amount_total <= 0:
        msgs.append("æˆäº¤é‡‘é¡ç¼ºå¤±")
    if inst_status != "READY":
        msgs.append("æ³•äººè³‡æ–™ä¸å¯ç”¨ï¼ˆå…è²»æ¨¡æ“¬æœŸï¼‰")
    if degraded_mode:
        msgs.append("è£æ±ºå±¤å·²é€²å…¥è³‡æ–™é™ç´šï¼šç¦æ­¢ BUY/TRIAL")
    else:
        msgs.append("è³‡æ–™ç‹€æ…‹å¯ç”¨ï¼ˆå…è¨±é€²å…¥å€‹è‚¡è£æ±ºï¼‰")

    # é¡¯ç¤ºä¾†æº/éŒ¯èª¤æ‘˜è¦ï¼ˆé¿å…å¤±çœŸï¼‰
    if amount_sources.get("error"):
        msgs.append(f"å®˜æ–¹æŠ“å–éŒ¯èª¤ï¼š{amount_sources.get('error')}")

    return "ï¼›".join(msgs) + "ã€‚"


def build_arbiter_input(
    market: str,
    session: str,
    display_trade_date: Optional[pd.Timestamp],
    amount_pack: Dict,
    amount_norm_pack: Dict,
    us_df: pd.DataFrame,
    fx_df: pd.DataFrame,
    top_df: pd.DataFrame,
    holdings: List[str],
) -> Dict:
    inst_status, inst_dates_3d = decide_inst_status_free()
    amount_total = amount_pack.get("amount_total", None)

    degraded_mode = decide_degraded_mode(amount_total=amount_total, inst_status=inst_status)

    macro_overview = {
        "trade_date": str(display_trade_date.date()) if display_trade_date is not None else None,
        "amount_twse": fmt_bn(to_bn_twd(amount_pack.get("amount_twse"))) if amount_pack.get("amount_twse") else "å¾…æ›´æ–°",
        "amount_tpex": fmt_bn(to_bn_twd(amount_pack.get("amount_tpex"))) if amount_pack.get("amount_tpex") else "å¾…æ›´æ–°",
        "amount_total": fmt_bn(to_bn_twd(amount_pack.get("amount_total"))) if amount_pack.get("amount_total") else "å¾…æ›´æ–°",
        "amount_sources": {
            "twse": amount_pack.get("sources", {}).get("twse"),
            "tpex": amount_pack.get("sources", {}).get("tpex"),
            "error": amount_pack.get("error"),
            "warning": amount_pack.get("warning"),
        },
        "progress": amount_norm_pack.get("progress"),
        "amount_norm_cum_ratio": amount_norm_pack.get("amount_norm_cum_ratio"),
        "amount_norm_slice_ratio": amount_norm_pack.get("amount_norm_slice_ratio"),
        "amount_norm_label": amount_norm_pack.get("amount_norm_label", "UNKNOWN"),
        "inst_status": inst_status,
        "inst_dates_3d": inst_dates_3d,
        "degraded_mode": degraded_mode,
        "data_mode": session,
        "market_comment": build_market_comment(
            amount_total=amount_total,
            inst_status=inst_status,
            degraded_mode=degraded_mode,
            data_mode=session,
            amount_sources=macro_overview["amount_sources"],
        ),
    }

    # Global æ‘˜è¦ï¼ˆåƒ…å–é—œéµæ¬„ä½ï¼‰
    def df_to_records(df: pd.DataFrame) -> List[Dict]:
        cols = [c for c in ["Name", "Symbol", "Date", "Close", "Chg%"] if c in df.columns]
        return df[cols].to_dict(orient="records")

    # Top listï¼ˆå«æŒå€‰ + å€™é¸ï¼‰
    top_records = []
    if not top_df.empty:
        for _, r in top_df.iterrows():
            sym = str(r.get("Symbol", ""))
            top_records.append({
                "Symbol": sym,
                "Name": str(r.get("Name", "")),
                "Price": safe_float(r.get("Close", np.nan), default=np.nan),
                "ranking": {
                    "rank": int(r.get("Rank", 0)) if not pd.isna(r.get("Rank", np.nan)) else None,
                    "tier": "A" if int(r.get("Rank", 999)) <= 20 else "B",
                    "top20_flag": True if int(r.get("Rank", 999)) <= 20 else False,
                },
                "Technical": {
                    "MA_Bias": round(safe_float(r.get("MA_Bias", 0.0)), 4),
                    "Vol_Ratio": round(safe_float(r.get("Vol_Ratio", 0.0)), 4),
                    "Score": round(safe_float(r.get("Score", 0.0)), 2),
                },
                "Institutional": {
                    "Inst_Status": "PENDING" if inst_status != "READY" else "READY"
                },
            })

    arb = {
        "meta": {
            "system": SYSTEM_NAME,
            "market": market,
            "timestamp": now_taipei().strftime("%Y-%m-%d %H:%M"),
            "session": session,
        },
        "macro": {
            "overview": macro_overview,
        },
        "global": {
            "us": df_to_records(us_df),
            "fx": df_to_records(fx_df),
        },
        "holdings": holdings,
        "stocks": top_records,
    }
    return arb


# ====== UI ======
def ui_header():
    st.set_page_config(page_title=APP_TITLE, layout="wide")
    st.title(APP_TITLE)


def ui_sidebar() -> Dict:
    st.sidebar.header("è¨­å®š")

    market = st.sidebar.selectbox("Market", ["tw-share"], index=0)

    session = st.sidebar.selectbox("Session", ["INTRADAY", "EOD"], index=1)

    # æŒå€‰ï¼šè¼¸å…¥ä»£ç¢¼ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰ï¼›æ”¯æ´ 2330 è‡ªå‹•è£œ .TW
    st.sidebar.subheader("æŒå€‰ï¼ˆæœƒç´å…¥è¿½è¹¤ï¼‰")
    raw_hold = st.sidebar.text_area("è¼¸å…¥ä»£ç¢¼ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰", value="2330.TW", height=90)
    holdings = []
    for x in raw_hold.split(","):
        s = _normalize_symbol(x)
        if s:
            holdings.append(s)
    holdings = sorted(list(dict.fromkeys(holdings)))  # å»é‡ä¸”ä¿åº

    # SSL ä»ç„¶ä¿ç•™ï¼ˆä½†æœ¬ç‰ˆä¸å¼·åˆ¶ç¹éï¼‰
    verify_ssl = st.sidebar.checkbox("SSL é©—è­‰ï¼ˆå®˜æ–¹è³‡æ–™ï¼‰", value=True)

    # å®˜æ–¹è³‡æ–™å›æº¯å¤©æ•¸ï¼šé ç•™æœªä¾†ç”¨ï¼ˆä¾‹å¦‚æŠ“ã€Œæœ€è¿‘å¯ç”¨äº¤æ˜“æ—¥ã€ï¼‰
    lookback = st.sidebar.slider("å®˜æ–¹è³‡æ–™å›æº¯å¤©æ•¸", min_value=3, max_value=30, value=10, step=1)

    run = st.sidebar.button("Run")

    st.sidebar.caption("å…è²»æ¨¡æ“¬æœŸï¼šæ³•äººè³‡æ–™ï¼ˆFinMindï¼‰ä¸ä½¿ç”¨ï¼Œé¿å… 402ã€‚")
    return {
        "market": market,
        "session": session,
        "holdings": holdings,
        "verify_ssl": verify_ssl,
        "lookback": lookback,
        "run": run,
    }


def main():
    ui_header()
    opts = ui_sidebar()

    market = opts["market"]
    session = opts["session"]
    holdings = opts["holdings"]
    verify_ssl = opts["verify_ssl"]

    # === ä¸»æµç¨‹ï¼ˆæ¯æ¬¡åˆ·æ–°éƒ½è·‘ï¼›ä¹Ÿå¯ä¾ run è§¸ç™¼ï¼Œé€™è£¡ä¸é˜»æ“‹ä»¥ä¿è³‡æ–™æœ€æ–°ï¼‰ ===
    now = now_taipei()
    st.info(f"ç›®å‰å°åŒ—æ™‚é–“ï¼š{now.strftime('%Y-%m-%d %H:%M')}ï½œæ¨¡å¼ï¼š{session}ï¼ˆé¡¯ç¤ºã€æœ€è¿‘å¯ç”¨äº¤æ˜“æ—¥ã€è³‡æ–™ï¼‰")

    # 1) è®€å–å°è‚¡ Universe CSVï¼ˆTop20ï¼‰
    try:
        df = load_market_df(market)
        td = latest_trade_date(df)
        if td is None:
            st.error("å°è‚¡è³‡æ–™æª”å­˜åœ¨ï¼Œä½† Date æ¬„ä½ç„¡æœ‰æ•ˆæ—¥æœŸã€‚è«‹ç¢ºèª CSV æ ¼å¼ã€‚")
            return
    except Exception as e:
        st.error(f"è®€å–å°è‚¡è³‡æ–™å¤±æ•—ï¼š{e}")
        return

    st.caption(f"é¡¯ç¤ºäº¤æ˜“æ—¥ï¼š{td.date()}ï¼ˆå¾è³‡æ–™æª”æœ€æ–°æ—¥æœŸæ¨å®šï¼‰")

    top20_df = build_top20(df, td)

    # 2) åœ‹éš›å¸‚å ´ï¼ˆç¾è‚¡/åŒ¯ç‡ï¼‰â€” æœ€æ–°å¯ç”¨äº¤æ˜“æ—¥
    us_df, fx_df = build_global_tables()

    st.subheader("å…¨çƒå¸‚å ´æ‘˜è¦ï¼ˆç¾è‚¡ï¼‰â€” æœ€æ–°å¯ç”¨äº¤æ˜“æ—¥æ”¶ç›¤")
    st.dataframe(us_df, use_container_width=True, hide_index=True)

    st.subheader("åŒ¯ç‡ï¼ˆåƒè€ƒï¼‰â€” æœ€æ–°å¯ç”¨äº¤æ˜“æ—¥")
    st.dataframe(fx_df, use_container_width=True, hide_index=True)

    # 3) æˆäº¤é‡‘é¡ï¼ˆå®˜æ–¹å£å¾‘ï¼šTWSE + TPExï¼‰
    st.subheader("å¸‚å ´æˆäº¤é‡‘é¡ï¼ˆå®˜æ–¹å£å¾‘ï¼šTWSE + TPEx = amount_totalï¼‰")

    amount_pack = fetch_official_amount(verify_ssl=verify_ssl)

    col1, col2, col3, col4 = st.columns(4)
    twse_bn = to_bn_twd(amount_pack.get("amount_twse"))
    tpex_bn = to_bn_twd(amount_pack.get("amount_tpex"))
    total_bn = to_bn_twd(amount_pack.get("amount_total"))

    col1.metric("TWSE ä¸Šå¸‚", fmt_bn(twse_bn))
    col2.metric("TPEx ä¸Šæ«ƒ", fmt_bn(tpex_bn))
    col3.metric("Total åˆè¨ˆ", fmt_bn(total_bn))
    col4.metric("å®˜æ–¹äº¤æ˜“æ—¥ï¼ˆæ¨å®šï¼‰", amount_pack.get("trade_date") or "æœªçŸ¥")

    st.caption(f"ä¾†æºï¼šTWSE={amount_pack.get('sources', {}).get('twse')}ï½œTPEx={amount_pack.get('sources', {}).get('tpex')}")
    if amount_pack.get("error"):
        st.warning(f"å®˜æ–¹æŠ“å–å¤±æ•—ï¼ˆä»å¯é¡¯ç¤ºå…¶ä»–å€å¡Šï¼‰ï¼š{amount_pack.get('error')}")

    # 4) é‡èƒ½æ­£è¦åŒ–ï¼ˆç›¤ä¸­/ç›¤å¾Œéƒ½å¯ç®—ï¼›avg20 ç›®å‰è‹¥ä½ æ²’æä¾›å°±æœƒæ˜¯ Noneï¼‰
    #   - æ¨¡æ“¬æœŸï¼šä»¥ã€Œæ²’æœ‰ avg20ã€è¦–ç‚º UNKNOWNï¼Œé¿å…å‡ç²¾æº–
    avg20_amount_total_median = None  # ä½ è‹¥æœ‰ 20D ä¸­ä½æ•¸ä¾†æºï¼Œæ”¾é€™è£¡
    amount_total_now = amount_pack.get("amount_total") or 0
    amount_norm = intraday_norm(
        amount_total_now=int(amount_total_now),
        amount_total_prev=None,
        avg20_amount_total=avg20_amount_total_median,
        now=now,
        alpha=0.65,
    )

    st.subheader("INTRADAY é‡èƒ½æ­£è¦åŒ–ï¼ˆé¿å…æ—©ç›¤èª¤åˆ¤ LOWï¼‰")
    st.json({
        "progress": amount_norm.get("progress"),
        "cum_ratio(ç©©å¥å‹ç”¨)": amount_norm.get("amount_norm_cum_ratio"),
        "slice_ratio(ä¿å®ˆå‹ç”¨)": amount_norm.get("amount_norm_slice_ratio"),
        "label": amount_norm.get("amount_norm_label"),
    })

    # 5) Top listï¼ˆRoute Aï¼šUniverse + æŒå€‰åˆä½µ = 20 + Nï¼‰
    st.subheader("Top Listï¼ˆRoute Aï¼šUniverse æ’å + æŒå€‰åˆä½µï¼‰")

    # åˆä½µæŒå€‰ï¼šè‹¥æŒå€‰ä¸åœ¨ top20 å…§ï¼Œè£œä¸€åˆ—ï¼ˆä»¥è©²æ—¥è³‡æ–™ç‚ºä¸»ï¼›æ‰¾ä¸åˆ°å°±ç•™ç©ºï¼‰
    top_symbols = set(top20_df["Symbol"].tolist()) if not top20_df.empty else set()
    add_rows = []
    for sym in holdings:
        if sym in top_symbols:
            continue
        hit = df[(df["Date"].dt.normalize() == td) & (df["Symbol"] == sym)]
        if hit.empty:
            add_rows.append({
                "Symbol": sym,
                "Name": symbol_to_name(sym),
                "Date": td,
                "Close": np.nan,
                "Volume": np.nan,
                "Vol_Ratio": np.nan,
                "MA_Bias": np.nan,
                "Score": np.nan,
                "Rank": None,
            })
        else:
            r = hit.iloc[0].to_dict()
            r["Rank"] = None
            add_rows.append(r)

    if add_rows:
        add_df = pd.DataFrame(add_rows)
        # æ¬„ä½å°é½Š
        for c in top20_df.columns:
            if c not in add_df.columns:
                add_df[c] = np.nan
        top_view = pd.concat([top20_df, add_df[top20_df.columns]], ignore_index=True)
    else:
        top_view = top20_df.copy()

    # æ¬„ä½æ•´ç†ï¼ˆä¸­æ–‡åç¨±æ¬„ï¼‰
    if "Name" not in top_view.columns:
        top_view["Name"] = top_view["Symbol"].map(symbol_to_name)

    # çµ±ä¸€ Date é¡¯ç¤º
    if "Date" in top_view.columns:
        top_view["Date"] = pd.to_datetime(top_view["Date"], errors="coerce").dt.strftime("%Y-%m-%d")

    show_cols = [c for c in [
        "Symbol", "Name", "Date", "Close", "Volume", "Vol_Ratio", "MA_Bias", "Score", "Rank"
    ] if c in top_view.columns]
    st.dataframe(top_view[show_cols], use_container_width=True, hide_index=True)

    # 6) Arbiter Inputï¼ˆå¯å›æº¯ + å¯è¤‡è£½ï¼‰
    st.subheader("AI JSONï¼ˆArbiter Inputï¼‰â€” å¯å›æº¯ï¼ˆæ¨¡æ“¬æœŸå…è²»ï¼‰")

    arbiter_input = build_arbiter_input(
        market=market,
        session=session,
        display_trade_date=td,
        amount_pack=amount_pack,
        amount_norm_pack=amount_norm,
        us_df=us_df,
        fx_df=fx_df,
        top_df=top20_df,
        holdings=holdings,
    )

    # äººçœ¼é–±è®€
    st.json(arbiter_input)

    # å·¥ç¨‹ç”¨ï¼šå¯è¤‡è£½
    st.markdown("#### ğŸ“‹ è¤‡è£½ç”¨ JSONï¼ˆå·¥ç¨‹ / Agent / å›æ¸¬ï¼‰")
    arbiter_json_str = json.dumps(arbiter_input, ensure_ascii=False, indent=2)
    st.code(arbiter_json_str, language="json")
    st.caption("â¬†ï¸ å³ä¸Šè§’ Copy å¯ç›´æ¥è¤‡è£½ï¼Œä½œç‚º Arbiter / Agent / å›æ¸¬ç³»çµ±è¼¸å…¥ã€‚")


if __name__ == "__main__":
    main()
