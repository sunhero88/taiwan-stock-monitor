import os
import json
import time
import logging
import re
from datetime import datetime
from typing import Optional, Tuple, Dict, Any, List

import pandas as pd
import requests
import yfinance as yf

# =========================
# åŸºæœ¬è¨­å®š
# =========================
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

MARKET_JSON = os.path.join(DATA_DIR, "market_amount.json")
STOCK_CSV = os.path.join(DATA_DIR, "data_tw-share.csv")

TIMEOUT = 15
RETRY = 3
SLEEP_BETWEEN = 1.2

# =========================
# å·¥å…·ï¼šæ•¸å­—è§£æ
# =========================
def _to_int_from_commas(s: str) -> Optional[int]:
    if s is None:
        return None
    s = s.strip()
    s = s.replace(",", "")
    if not s or s in ("--", "null", "None"):
        return None
    try:
        return int(float(s))
    except Exception:
        return None

def _is_tpex_errors_url(url: str) -> bool:
    if not url:
        return False
    return "tpex.org.tw/errors" in url

# =========================
# 1) TWSE æˆäº¤é‡‘é¡ï¼šå®˜æ–¹ STOCK_DAY_ALL åŠ ç¸½
# =========================
def fetch_twse_amount(trade_date_yyyymmdd: str) -> Tuple[Optional[int], Dict[str, Any]]:
    """
    å›å‚³ (amount_twse, audit)
    """
    url = "https://www.twse.com.tw/exchangeReport/STOCK_DAY_ALL"
    params = {"response": "json", "date": trade_date_yyyymmdd}

    audit: Dict[str, Any] = {
        "market": "TWSE",
        "trade_date": f"{trade_date_yyyymmdd[:4]}-{trade_date_yyyymmdd[4:6]}-{trade_date_yyyymmdd[6:8]}",
        "url": url,
        "params": params,
        "status_code": None,
        "final_url": None,
        "rows": None,
        "missing_amount_rows": None,
        "amount_sum": None,
        "amount_col": "æˆäº¤é‡‘é¡",
    }

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept": "application/json,text/plain,*/*",
        "Referer": "https://www.twse.com.tw/",
    }

    for k in range(1, RETRY + 1):
        try:
            r = requests.get(url, params=params, headers=headers, timeout=TIMEOUT)
            audit["status_code"] = r.status_code
            audit["final_url"] = r.url

            r.raise_for_status()
            js = r.json()
            data = js.get("data", [])
            fields = js.get("fields", [])

            if not isinstance(data, list) or not fields:
                raise ValueError("TWSE JSON çµæ§‹ç•°å¸¸ï¼šç¼ºå°‘ data/fields")

            # æ‰¾åˆ°ã€Œæˆäº¤é‡‘é¡ã€æ¬„ä½ç´¢å¼•
            try:
                idx_amount = fields.index("æˆäº¤é‡‘é¡")
            except ValueError:
                # æœ‰æ™‚æ¬„ä½åç¨±å¯èƒ½ä¸åŒï¼ˆæ¥µå°‘ï¼‰ï¼Œä¿å®ˆè™•ç†
                raise ValueError(f"TWSE fields æ‰¾ä¸åˆ°ã€æˆäº¤é‡‘é¡ã€æ¬„ä½ï¼Œfields={fields}")

            amount_sum = 0
            missing = 0
            for row in data:
                v = row[idx_amount] if idx_amount < len(row) else None
                vi = _to_int_from_commas(str(v)) if v is not None else None
                if vi is None:
                    missing += 1
                    continue
                amount_sum += vi

            audit["rows"] = len(data)
            audit["missing_amount_rows"] = missing
            audit["amount_sum"] = amount_sum

            return amount_sum, audit

        except Exception as e:
            logging.warning(f"TWSE æŠ“å–å¤±æ•— (try {k}/{RETRY}): {e}")
            time.sleep(SLEEP_BETWEEN * k)

    return None, audit

# =========================
# 2) TPEX æˆäº¤é‡‘é¡ï¼šå…ˆ primeï¼Œå†æ‰“ resultï¼Œé¿å… /errors
# =========================
def fetch_tpex_amount(roc_date: str) -> Tuple[Optional[int], Dict[str, Any]]:
    """
    roc_date ä¾‹ï¼š'115/02/06'
    å›å‚³ (amount_tpex, audit)

    æ ¸å¿ƒç­–ç•¥ï¼š
    - å…ˆ GET st43.php primeï¼ˆæ‹¿ cookie / sessionï¼‰
    - å† GET st43_result.php
    - è£œé½Š User-Agent / Referer / Accept-Language
    - è‹¥è¢«å°åˆ° /errors â†’ è¦–ç‚ºå¤±æ•—ä¸¦æ› se åƒæ•¸é‡è©¦
    """
    prime_url = "https://www.tpex.org.tw/web/stock/aftertrading/daily_trading_info/st43.php"
    result_url = "https://www.tpex.org.tw/web/stock/aftertrading/daily_trading_info/st43_result.php"

    # se å¯èƒ½å› ç«™å…§åˆ‡æ›è€Œä¸åŒï¼›å¸¸è¦‹å€¼ï¼šAL / EWï¼ˆä½ åŸæœ¬ç”¨ EWï¼‰
    se_candidates = ["EW", "AL", "ES"]

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.6",
        "Connection": "keep-alive",
        "Referer": "https://www.tpex.org.tw/zh-tw/mainboard/trading/info/stock-pricing.html",
    }

    audit: Dict[str, Any] = {
        "market": "TPEX",
        "roc_date": roc_date,
        "prime": {"url": prime_url, "status_code": None, "final_url": None},
        "result": [],
        "chosen": None,
        "status": "FAIL",
        "reason": None,
    }

    sess = requests.Session()
    sess.headers.update(headers)

    # å…ˆ primeï¼ˆéå¸¸é—œéµï¼šå¾ˆå¤šæƒ…æ³ä¸ prime ç›´æ¥æ‰“ result å°±æœƒè¢«ä¸Ÿ /errorsï¼‰
    try:
        pr = sess.get(prime_url, params={"l": "zh-tw"}, timeout=TIMEOUT, allow_redirects=True)
        audit["prime"]["status_code"] = pr.status_code
        audit["prime"]["final_url"] = pr.url
    except Exception as e:
        audit["reason"] = f"PRIME_FAIL: {e}"
        return None, audit

    for se in se_candidates:
        params = {"l": "zh-tw", "d": roc_date, "se": se}
        one_try = {
            "url": result_url,
            "params": params,
            "status_code": None,
            "final_url": None,
            "hit_errors": None,
            "parsed_amount": None,
        }

        for k in range(1, RETRY + 1):
            try:
                rr = sess.get(result_url, params=params, timeout=TIMEOUT, allow_redirects=True)
                one_try["status_code"] = rr.status_code
                one_try["final_url"] = rr.url
                one_try["hit_errors"] = _is_tpex_errors_url(rr.url)

                if one_try["hit_errors"]:
                    raise RuntimeError("TPEX redirected to /errors")

                html = rr.text or ""
                # å¸¸è¦‹é é¢æœƒå‡ºç¾ã€Œæˆäº¤é‡‘é¡ã€æ¬„ä½ï¼›ç”¨æ­£è¦å¼æŠ“è©²åˆ—æ•¸å€¼ï¼ˆæœ€ä¿å®ˆå¯«æ³•ï¼‰
                # ç”±æ–¼ç‰ˆé¢å¯èƒ½è®Šå‹•ï¼Œé€™è£¡æ¡ã€Œå…ˆæ‰¾ã€æˆäº¤é‡‘é¡ã€é™„è¿‘çš„ç¬¬ä¸€å€‹åƒåˆ†ä½æ•¸å­—ã€
                m = re.search(r"æˆäº¤é‡‘é¡[^0-9]{0,50}([0-9][0-9,]{3,})", html)
                if not m:
                    # å‚™æ´ï¼šæŠ“æ•´é æœ€å¤§çš„ä¸€å€‹åƒæˆäº¤é‡‘é¡çš„æ•¸å­—ï¼ˆé€šå¸¸æˆäº¤é‡‘é¡é‡ç´šæœ€å¤§ï¼‰
                    nums = re.findall(r"\b[0-9][0-9,]{6,}\b", html)  # è‡³å°‘ç™¾è¬ç­‰ç´š
                    if not nums:
                        raise ValueError("TPEX HTML æ‰¾ä¸åˆ°å¯è§£ææ•¸å­—")
                    # å–æœ€å¤§å€¼
                    cand = max((_to_int_from_commas(x) or 0) for x in nums)
                    if cand <= 0:
                        raise ValueError("TPEX è§£æçµæœç‚º 0/ç„¡æ•ˆ")
                    amount = cand
                else:
                    amount = _to_int_from_commas(m.group(1))
                    if not amount or amount <= 0:
                        raise ValueError("TPEX æˆäº¤é‡‘é¡è§£æå¤±æ•—/ç‚º 0")

                one_try["parsed_amount"] = amount
                audit["result"].append(one_try)

                audit["chosen"] = {"se": se, "amount": amount}
                audit["status"] = "OK"
                audit["reason"] = "OK"
                return amount, audit

            except Exception as e:
                logging.warning(f"TPEX æŠ“å–å¤±æ•— se={se} (try {k}/{RETRY}): {e}")
                time.sleep(SLEEP_BETWEEN * k)

        audit["result"].append(one_try)

    audit["reason"] = "ALL_SE_FAILED_or_WAF"
    return None, audit

# =========================
# 3) é‰…äº¨ APIï¼ˆå¯é¸ï¼‰ï¼šåƒ…ç•¶ä½œé¡å¤–è³‡è¨Šï¼Œä¸ä½œç‚ºå”¯ä¸€æˆäº¤é¡ä¾†æº
#    ä½ åŸæœ¬çš„ endpoint å…¶å¯¦æ˜¯ã€Œmainland/index/quoteã€ï¼Œå®¹æ˜“ä¸å°é¡Œ
#    è‹¥ä½ è¦ç•™é‰…äº¨ï¼Œå»ºè­°æ”¹æˆçœŸæ­£å°è‚¡/æŒ‡æ•¸å°æ‡‰çš„ç«¯é»ï¼ˆæ­¤è™•å…ˆä¸ç¡¬å¯«æ¨ä¼°ï¼‰
# =========================
def try_cnyes_placeholder() -> Tuple[Optional[int], Optional[int], str]:
    # é€™è£¡ä¿ç•™ä»‹é¢ï¼Œä½†ä¸å†ç”¨ã€Œä¸ç¢ºå®šç«¯é»ã€ç›´æ¥ç•¶æˆäº¤é¡
    return None, None, "CNYES_DISABLED_NO_GUESS"

# =========================
# 4) å€‹è‚¡ä¸‹è¼‰ï¼ˆç¶­æŒä½ åŸæœ¬çš„ç©©å®šç­–ç•¥ + å–®é»æ•‘æ´ï¼‰
# =========================
def download_stocks(tickers: List[str]) -> List[Dict[str, Any]]:
    logging.info(f"æ­£åœ¨ä¸‹è¼‰ {len(tickers)} æª”å€‹è‚¡ï¼ˆyfinance, threads=Falseï¼‰...")
    raw = yf.download(tickers, period="10d", interval="1d", threads=False, progress=False)

    out: List[Dict[str, Any]] = []
    for sym in tickers:
        try:
            close_price = raw["Close"][sym].dropna().iloc[-1]
            volume = raw["Volume"][sym].dropna().iloc[-1]
            out.append({"Symbol": sym, "Price": float(close_price), "Volume": int(volume)})
        except Exception:
            logging.info(f"ğŸ”§ å–®ç¨æ•‘æ´ {sym} ...")
            single = yf.Ticker(sym).history(period="5d")
            if not single.empty and "Close" in single and "Volume" in single:
                out.append({"Symbol": sym, "Price": float(single["Close"].iloc[-1]), "Volume": int(single["Volume"].iloc[-1])})
            else:
                out.append({"Symbol": sym, "Price": None, "Volume": None})
    return out

# =========================
# 5) ä¸»ç¨‹å¼ï¼šå¯«å…¥ market_amount.json + data_tw-share.csv
# =========================
def main():
    # ä»¥ã€Œä»Šå¤©ã€ç‚ºé è¨­ï¼›è‹¥ä½ è¦ç”¨æŒ‡å®šäº¤æ˜“æ—¥ï¼Œæ”¹é€™è£¡å³å¯
    trade_date = datetime.now().strftime("%Y-%m-%d")
    yyyymmdd = trade_date.replace("-", "")

    # ROC æ—¥æœŸï¼ˆæ°‘åœ‹ï¼‰: è¥¿å…ƒå¹´-1911
    y = int(trade_date[:4]) - 1911
    roc_date = f"{y}/{trade_date[5:7]}/{trade_date[8:10]}"

    # (A) å®˜æ–¹ TWSE
    twse_amount, twse_audit = fetch_twse_amount(yyyymmdd)
    if twse_amount:
        logging.info(f"TWSE æˆäº¤é¡: {twse_amount:,}ï¼ˆç´„ {twse_amount/1e8:.1f} å„„ï¼‰")
    else:
        logging.warning("TWSE æˆäº¤é¡æŠ“å–å¤±æ•—ã€‚")

    # (B) å®˜æ–¹ TPEXï¼ˆprime + resultï¼‰
    tpex_amount, tpex_audit = fetch_tpex_amount(roc_date)
    if tpex_amount:
        logging.info(f"TPEX æˆäº¤é¡: {tpex_amount:,}ï¼ˆç´„ {tpex_amount/1e8:.1f} å„„ï¼‰")
    else:
        logging.warning("TPEX æˆäº¤é¡ä»æŠ“ä¸åˆ°ï¼ˆå¯èƒ½ WAF/å°æµï¼‰ã€‚")

    # (C) å€‹è‚¡
    tickers = [
        "2330.TW","2317.TW","2454.TW","2308.TW","2382.TW","3231.TW","2376.TW","3017.TW","3324.TW","3661.TW",
        "2881.TW","2882.TW","2891.TW","2886.TW","2603.TW","2609.TW","1605.TW","1513.TW","1519.TW","2002.TW"
    ]
    stock_results = download_stocks(tickers)

    # (D) Integrity
    price_null = sum(1 for x in stock_results if x.get("Price") is None)
    vol_null = sum(1 for x in stock_results if x.get("Volume") is None)

    amount_total = (twse_amount or 0) + (tpex_amount or 0)
    status = "OK" if (twse_amount is not None and tpex_amount is not None) else "DEGRADED"
    amount_scope = "FULL" if (twse_amount is not None and tpex_amount is not None) else ("TWSE_ONLY" if twse_amount is not None else "NONE")

    market_output = {
        "trade_date": trade_date,
        "amount_twse": twse_amount,
        "amount_tpex": tpex_amount,
        "amount_total": amount_total if amount_total > 0 else None,
        "status": status,
        "amount_scope": amount_scope,
        "integrity": {
            "price_null": price_null,
            "volume_null": vol_null,
            "note": "TPEX è‹¥ç‚º nullï¼šä»£è¡¨è¢«å°åˆ° /errors æˆ– HTML çµæ§‹ç„¡æ³•è§£æï¼›æœ¬ç¨‹å¼ä¸åšæ¨ä¼°ï¼Œç¶­æŒé™ç´šã€‚",
        },
        "audit": {
            "twse": twse_audit,
            "tpex": tpex_audit,
        }
    }

    with open(MARKET_JSON, "w", encoding="utf-8") as f:
        json.dump(market_output, f, indent=2, ensure_ascii=False)

    df_stocks = pd.DataFrame(stock_results)
    df_stocks.to_csv(STOCK_CSV, index=False, encoding="utf-8-sig")

    logging.info(f"è¼¸å‡ºå®Œæˆï¼š{MARKET_JSON}, {STOCK_CSV}")
    logging.info(f"å¸‚å ´ç‹€æ…‹={status} / amount_scope={amount_scope} / amount_total={(market_output['amount_total'] or 0):,}")

if __name__ == "__main__":
    main()
